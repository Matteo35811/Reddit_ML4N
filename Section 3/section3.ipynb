{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "793d0aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ everything is working\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ everything is working\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03a73108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Imports OK \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c06938fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments: 1107946\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>body_normalized</th>\n",
       "      <th>body_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ejchristian86</td>\n",
       "      <td>TwoXChromosomes</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>I hadn't ever heard of them before joining thi...</td>\n",
       "      <td>i hadn't ever heard of them before joining thi...</td>\n",
       "      <td>hear join subreddit big thing apparently commo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZenDragon</td>\n",
       "      <td>gaming</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>At 7680 by 4320 with 64x AA, right?</td>\n",
       "      <td>at 7680 by 4320 with 64x aa, right?</td>\n",
       "      <td>7680 4320 64x aa right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>savoytruffle</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>bite me</td>\n",
       "      <td>bite me</td>\n",
       "      <td>bite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hentercenter</td>\n",
       "      <td>stlouisblues</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>Damn that was a good penalty :(</td>\n",
       "      <td>damn that was a good penalty :(</td>\n",
       "      <td>damn good penalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rick-o-suave</td>\n",
       "      <td>army</td>\n",
       "      <td>1.388534e+09</td>\n",
       "      <td>I swore into DEP on 6-OCT and I left 5-NOV und...</td>\n",
       "      <td>i swore into dep on 6-oct and i left 5-nov und...</td>\n",
       "      <td>swear dep 6 oct leave 5 nov 18x contract month...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author        subreddit   created_utc  \\\n",
       "0  ejchristian86  TwoXChromosomes  1.388534e+09   \n",
       "1      ZenDragon           gaming  1.388534e+09   \n",
       "2   savoytruffle        AskReddit  1.388534e+09   \n",
       "3   hentercenter     stlouisblues  1.388534e+09   \n",
       "4   rick-o-suave             army  1.388534e+09   \n",
       "\n",
       "                                                body  \\\n",
       "0  I hadn't ever heard of them before joining thi...   \n",
       "1                At 7680 by 4320 with 64x AA, right?   \n",
       "2                                            bite me   \n",
       "3                    Damn that was a good penalty :(   \n",
       "4  I swore into DEP on 6-OCT and I left 5-NOV und...   \n",
       "\n",
       "                                     body_normalized  \\\n",
       "0  i hadn't ever heard of them before joining thi...   \n",
       "1                at 7680 by 4320 with 64x aa, right?   \n",
       "2                                            bite me   \n",
       "3                    damn that was a good penalty :(   \n",
       "4  i swore into dep on 6-oct and i left 5-nov und...   \n",
       "\n",
       "                                          body_clean  \n",
       "0  hear join subreddit big thing apparently commo...  \n",
       "1                             7680 4320 64x aa right  \n",
       "2                                               bite  \n",
       "3                                  damn good penalty  \n",
       "4  swear dep 6 oct leave 5 nov 18x contract month...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned unsupervised dataset\n",
    "df_unsup = pd.read_csv(\"../Section 1/clean_unsupervised.csv\")\n",
    "\n",
    "print(\"Number of comments:\", len(df_unsup))\n",
    "df_unsup.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db62f912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.092674e+06\n",
       "mean     8.088918e+01\n",
       "std      1.415220e+02\n",
       "min      1.000000e+00\n",
       "25%      2.300000e+01\n",
       "50%      5.700000e+01\n",
       "75%      7.500000e+01\n",
       "max      1.079900e+04\n",
       "Name: body_clean, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unsup['body_clean'].str.len().describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "348c6ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_unsup.sample(\n",
    "    n=100_000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Clean missing or empty documents\n",
    "df_sample = df_sample.dropna(subset=['body_clean'])\n",
    "df_sample = df_sample[df_sample['body_clean'].str.strip() != \"\"]\n",
    "df_sample['body_clean'] = df_sample['body_clean'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e77b9c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98597"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3625c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4761957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98597, 10000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.5,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X = tfidf.fit_transform(df_sample['body_clean'])\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d965b292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98597, 50)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_components = 50\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "X_reduced = svd.fit_transform(X)\n",
    "X_reduced.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5bff3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 6, ..., 6, 6, 6], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 10\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(X_reduced)\n",
    "\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "718eac12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>body_normalized</th>\n",
       "      <th>body_clean</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lokikong</td>\n",
       "      <td>IAmA</td>\n",
       "      <td>1.388696e+09</td>\n",
       "      <td>I think you mean \"*Pass* the pipe.\"</td>\n",
       "      <td>i think you mean \"*pass* the pipe.\"</td>\n",
       "      <td>think mean pass pipe</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MrN4T3</td>\n",
       "      <td>projectcar</td>\n",
       "      <td>1.390693e+09</td>\n",
       "      <td>No I've just put so much work into it trying t...</td>\n",
       "      <td>no i've just put so much work into it trying t...</td>\n",
       "      <td>work try ready event happen lose expect 50 dol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3chnopsycho</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>1.389039e+09</td>\n",
       "      <td>Sweden is not Switzerland ;) \\n\\nOtherwise I a...</td>\n",
       "      <td>sweden is not switzerland ;) otherwise i agree...</td>\n",
       "      <td>sweden switzerland agree like user post switze...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1EyedPokerface</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1.389594e+09</td>\n",
       "      <td>ah I will sleep better after reading that</td>\n",
       "      <td>ah i will sleep better after reading that</td>\n",
       "      <td>ah sleep well read</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not_a_ZED</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>1.389288e+09</td>\n",
       "      <td>Yep. Time to upgrade to a monitor mount.</td>\n",
       "      <td>yep. time to upgrade to a monitor mount.</td>\n",
       "      <td>yep time upgrade monitor mount</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author          subreddit   created_utc  \\\n",
       "0        Lokikong               IAmA  1.388696e+09   \n",
       "1          MrN4T3         projectcar  1.390693e+09   \n",
       "2    T3chnopsycho  explainlikeimfive  1.389039e+09   \n",
       "3  1EyedPokerface          AskReddit  1.389594e+09   \n",
       "4       Not_a_ZED       pcmasterrace  1.389288e+09   \n",
       "\n",
       "                                                body  \\\n",
       "0                I think you mean \"*Pass* the pipe.\"   \n",
       "1  No I've just put so much work into it trying t...   \n",
       "2  Sweden is not Switzerland ;) \\n\\nOtherwise I a...   \n",
       "3          ah I will sleep better after reading that   \n",
       "4           Yep. Time to upgrade to a monitor mount.   \n",
       "\n",
       "                                     body_normalized  \\\n",
       "0                i think you mean \"*pass* the pipe.\"   \n",
       "1  no i've just put so much work into it trying t...   \n",
       "2  sweden is not switzerland ;) otherwise i agree...   \n",
       "3          ah i will sleep better after reading that   \n",
       "4           yep. time to upgrade to a monitor mount.   \n",
       "\n",
       "                                          body_clean  cluster  \n",
       "0                               think mean pass pipe        5  \n",
       "1  work try ready event happen lose expect 50 dol...        1  \n",
       "2  sweden switzerland agree like user post switze...        6  \n",
       "3                                 ah sleep well read        6  \n",
       "4                     yep time upgrade monitor mount        6  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df_sample.reset_index(drop=True)\n",
    "df_sample[\"cluster\"] = labels\n",
    "df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcae399a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0     6008\n",
       "1    10726\n",
       "2     9050\n",
       "3     3416\n",
       "4     1865\n",
       "5     7247\n",
       "6    54955\n",
       "7     1175\n",
       "8     3106\n",
       "9     1049\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[\"cluster\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16886d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6      :( I'm sorry they rejected it. I guess it is d...\n",
       "16     &gt; I'm the Al Queda of the anti gun movement...\n",
       "20     The scent of bourjois is pretty strong and if ...\n",
       "37     Looks like this got caught in the spam filter....\n",
       "66     That's actually where my husband got the name ...\n",
       "67     Do you ever do a reveal at the end of the conv...\n",
       "93     \"Go fuck yourself, poor people!\"\\n\\nThis will ...\n",
       "97     This is rather sad because it is true. I would...\n",
       "120    How about the pointed pronunciation of the let...\n",
       "135    EXACTLY. and i don't like how jerky their move...\n",
       "136    It looks like Boone is just beating the shit o...\n",
       "140    Sourced here: https://play.google.com/store/ap...\n",
       "159    Looks like a fence because the dog looks like ...\n",
       "171    Yeah, there are a couple of different mechanis...\n",
       "201    Shit I can't like this more than once. I'd giv...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[df_sample[\"cluster\"] == 0][\"body\"].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d863a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      No I've just put so much work into it trying t...\n",
       "13     No I've just put so much work into it trying t...\n",
       "30     No I've just put so much work into it trying t...\n",
       "32     No I've just put so much work into it trying t...\n",
       "45     No I've just put so much work into it trying t...\n",
       "52     No I've just put so much work into it trying t...\n",
       "59     No I've just put so much work into it trying t...\n",
       "75     No I've just put so much work into it trying t...\n",
       "88     No I've just put so much work into it trying t...\n",
       "92     No I've just put so much work into it trying t...\n",
       "95     No I've just put so much work into it trying t...\n",
       "101    No I've just put so much work into it trying t...\n",
       "103    No I've just put so much work into it trying t...\n",
       "106    No I've just put so much work into it trying t...\n",
       "128    No I've just put so much work into it trying t...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[df_sample[\"cluster\"] == 1][\"body\"].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da49100a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      Glad it went fairly smoothly. I was a bridesma...\n",
       "8      Glad it went fairly smoothly. I was a bridesma...\n",
       "10     Glad it went fairly smoothly. I was a bridesma...\n",
       "15     Glad it went fairly smoothly. I was a bridesma...\n",
       "23     Glad it went fairly smoothly. I was a bridesma...\n",
       "40     Glad it went fairly smoothly. I was a bridesma...\n",
       "41     Glad it went fairly smoothly. I was a bridesma...\n",
       "63     Glad it went fairly smoothly. I was a bridesma...\n",
       "102    Glad it went fairly smoothly. I was a bridesma...\n",
       "112    Glad it went fairly smoothly. I was a bridesma...\n",
       "113    Glad it went fairly smoothly. I was a bridesma...\n",
       "124    Glad it went fairly smoothly. I was a bridesma...\n",
       "130    Glad it went fairly smoothly. I was a bridesma...\n",
       "153    Glad it went fairly smoothly. I was a bridesma...\n",
       "157    Glad it went fairly smoothly. I was a bridesma...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[df_sample[\"cluster\"] == 2][\"body\"].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29d5b9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19     Though not a yank \n",
       "21     Though not a yank \n",
       "34     Though not a yank \n",
       "42     Though not a yank \n",
       "94     Though not a yank \n",
       "114    Though not a yank \n",
       "164    Though not a yank \n",
       "168    Though not a yank \n",
       "173    Though not a yank \n",
       "182    Though not a yank \n",
       "194    Though not a yank \n",
       "210    Though not a yank \n",
       "221    Though not a yank \n",
       "222    Though not a yank \n",
       "248    Though not a yank \n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[df_sample[\"cluster\"] == 3][\"body\"].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c1b40cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29     Yep I sure do game. Been a gamer since I was m...\n",
       "58      I'm 95% sure I saw this picture on my newsfeed. \n",
       "100    Once again. Thanks for the input. I'm going to...\n",
       "117                                 &gt; Not sure \\n\\n:)\n",
       "237        That's pretty much my reaction when losing...\n",
       "239    Eh, Kiko Alonso was pretty beastly.  He plays ...\n",
       "244    I thought maybe Karo light corn syrup was what...\n",
       "253    If you're looking at it from a B movie perspec...\n",
       "312    Because I don't need to be. I'm fine with the ...\n",
       "369    Pretty much never. It's just not something I n...\n",
       "503    i've missed last call for sure, though there i...\n",
       "523    Thin knee high socks should do the trick! They...\n",
       "537    I warned all the younger women there (all fami...\n",
       "596    Im not sure of anything. I posted pictures... ...\n",
       "625    Pretty sure that Bodies by Drowning Pool has n...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[df_sample[\"cluster\"] == 4][\"body\"].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3eae07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    I think you mean \"*Pass* the pipe.\"\n",
       "7      I know we shouldn't trust Twitter but I've hea...\n",
       "35      Seriously, just call them southwest. There's ...\n",
       "78     I prefer the more upbeat version from *Going P...\n",
       "80     I suppose it's possible. I've never had that h...\n",
       "81     Thank you! The thing I need clarifying is: how...\n",
       "89     &gt;embrace the grind, lower your shoulder and...\n",
       "105    I know a few people that enjoy yoga but don't ...\n",
       "108    There have been WAY too many of these ads post...\n",
       "138    Exactly. That's why I wouldn't feel awkward be...\n",
       "186    This is really the wrong sub in which to attem...\n",
       "202    I see it as a way of donating to a website I u...\n",
       "228           If only we could all think for ourselves! \n",
       "235    Untrue. I've done it on numerous occasions. Lo...\n",
       "243    Ah... yeah.... I think I am kind of average on...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[df_sample[\"cluster\"] == 5][\"body\"].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5eaa2a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     Sweden is not Switzerland ;) \\n\\nOtherwise I a...\n",
       "3             ah I will sleep better after reading that\n",
       "4              Yep. Time to upgrade to a monitor mount.\n",
       "9                    how are you going to learn though?\n",
       "11    [Nom Nom Nom](http://www.youtube.com/watch?v=m...\n",
       "12    Would you have someone shuffle the deck one wa...\n",
       "14    While I don't believe in the feminist idea of ...\n",
       "17    So I was picking you up in 30 minutes. You loo...\n",
       "18       You are not a virgin in any sense of the word.\n",
       "22    As long as they don't take our nieces, they ca...\n",
       "24                      You walked out of the theatre? \n",
       "25    Okay, you're right. 95% of what she does, the ...\n",
       "26    I never said you should buy.  I said the cheap...\n",
       "27                                 Bottle up economics.\n",
       "28                             Nite nite stalwart shibe\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[df_sample[\"cluster\"] == 6][\"body\"].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffafba5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91                Thanks. :p Finally someone understands!\n",
       "141                                          Aww, thanks!\n",
       "209     Wow. I was not expecting that. Thanks man! I'l...\n",
       "220            Thank you for keeping me in your thoughts \n",
       "372     LOL. I can see why that could be confusing. \\n...\n",
       "448                                      Ok cool, thanks!\n",
       "571                this is a really neat site thanks :)))\n",
       "649     This is absolutely amazing, I can't believe th...\n",
       "740                                                Thanks\n",
       "839                               lol, its okay.  Thanks.\n",
       "853     Thank you! \\n\\n[Wohoo!](https://24.media.tumbl...\n",
       "1005                                              Thanks!\n",
       "1038                                              Thanks!\n",
       "1053                                   Well damn. Thanks!\n",
       "1275    He's not on sleep meds. That was useful info t...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[df_sample[\"cluster\"] == 7][\"body\"].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "731422ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50     I have no idea man. Best bet is to google. I h...\n",
       "147                         Zotac is *clearly* the best.\n",
       "149    Doesn't Harry just have some of the traits of ...\n",
       "151                                           Good luck!\n",
       "175    &gt;How do you keep from going crazy during th...\n",
       "176    I like Crutchfield, and I'm sure other people ...\n",
       "190    That's a good comparison, there have to be sta...\n",
       "259    It was kind of lame when his girlfriend was An...\n",
       "394       Best ride at the garage, aside from your mom. \n",
       "472                               poolerino is good too.\n",
       "510    the part i love the best is where he saves up ...\n",
       "512                                       u looking good\n",
       "528    Fell for her in middle school, never let go. T...\n",
       "589    Gosh, I always forget how long he's been broad...\n",
       "637    Have you perchance played The Stanley Parable?...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[df_sample[\"cluster\"] == 8][\"body\"].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9ba4c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46      What the fuck? I don't see how people are okay...\n",
       "373     That isn't true everywhere, and \"most of the w...\n",
       "377     more importantly, have you seen [the video](ht...\n",
       "529     I enjoy both a lot! It's not something I learn...\n",
       "803                                  ''Hey, wanna fuck?''\n",
       "985                         This fight is classy as fuck.\n",
       "994     But notice that the Japanese don't give a fuck...\n",
       "1152    I'm actually happy to go back...\\n\\nI'm bored ...\n",
       "1327                                        Fuck I'm old \n",
       "1391    Wait, a dude called her a \"stripper whore\" and...\n",
       "1404                            Fuck no. Are you insane!?\n",
       "1525    Fuck SeaWorld. I was just in Orlando and I fli...\n",
       "1721    what the flying fuck is that i nthe background...\n",
       "1827                                          Holey fuck.\n",
       "1872    Not being selfish at all, some people are just...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[df_sample[\"cluster\"] == 9][\"body\"].head(15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
