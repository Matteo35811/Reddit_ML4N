{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Bag of Subreddits Feature Engineering\n",
                "\n",
                "This notebook implements the **posting pattern** feature extraction as described in point 3.c of the assignment.\n",
                "\n",
                "The idea is to create a feature vector for each user where each column represents the **fraction of times the user has posted in the x-th subreddit**. We focus on the **Top 15 subreddits** to reduce dimensionality.\n",
                "\n",
                "## Approach:\n",
                "1. Load the supervised dataset with subreddit information\n",
                "2. Identify the top 15 most popular subreddits\n",
                "3. For each author, compute the fraction of posts in each of the top 15 subreddits\n",
                "4. Create a \"Bag of Subreddits\" feature matrix\n",
                "5. Save features for use in model training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import sys\n",
                "\n",
                "sys.path.append(\"../source\")\n",
                "from src import stratified_split"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step1-header",
            "metadata": {},
            "source": [
                "## Step 1: Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load-data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the original supervised dataset (which contains subreddit information)\n",
                "df_supervised = pd.read_csv(\"../data/data_supervised.csv\")\n",
                "\n",
                "# Load target labels\n",
                "target_df = pd.read_csv(\"./Data/target_supervised.csv\")\n",
                "\n",
                "print(f\"Total comments: {len(df_supervised)}\")\n",
                "print(f\"Total authors in target: {len(target_df)}\")\n",
                "print(f\"\\nDataset columns: {df_supervised.columns.tolist()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "check-subreddits",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check subreddit distribution\n",
                "print(f\"Unique subreddits: {df_supervised['subreddit'].nunique()}\")\n",
                "print(f\"\\nTop 20 subreddits:\")\n",
                "print(df_supervised['subreddit'].value_counts().head(20))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step2-header",
            "metadata": {},
            "source": [
                "## Step 2: Identify Top 15 Subreddits"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "top15-subreddits",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the top 15 most popular subreddits\n",
                "TOP_N = 15\n",
                "\n",
                "subreddit_counts = df_supervised['subreddit'].value_counts()\n",
                "top_15_subreddits = subreddit_counts.head(TOP_N).index.tolist()\n",
                "\n",
                "print(f\"Top {TOP_N} Subreddits:\")\n",
                "for i, sub in enumerate(top_15_subreddits, 1):\n",
                "    count = subreddit_counts[sub]\n",
                "    percentage = (count / len(df_supervised)) * 100\n",
                "    print(f\"{i:2d}. {sub:30s} - {count:6d} posts ({percentage:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "visualize-top15",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize top 15 subreddits\n",
                "plt.figure(figsize=(12, 6))\n",
                "top_15_data = subreddit_counts.head(TOP_N)\n",
                "sns.barplot(x=top_15_data.values, y=top_15_data.index, palette='viridis')\n",
                "plt.xlabel('Number of Posts')\n",
                "plt.ylabel('Subreddit')\n",
                "plt.title(f'Top {TOP_N} Subreddits by Post Count')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step3-header",
            "metadata": {},
            "source": [
                "## Step 3: Create Bag of Subreddits Feature Matrix\n",
                "\n",
                "For each author, we compute the fraction of their posts that belong to each of the top 15 subreddits."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "compute-fractions",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_bag_of_subreddits(df, top_subreddits):\n",
                "    \"\"\"\n",
                "    Create a Bag of Subreddits feature matrix.\n",
                "    \n",
                "    For each author, computes the fraction of their posts in each of the top subreddits.\n",
                "    \n",
                "    Parameters:\n",
                "    -----------\n",
                "    df : pd.DataFrame\n",
                "        DataFrame with 'author' and 'subreddit' columns\n",
                "    top_subreddits : list\n",
                "        List of top subreddit names to use as features\n",
                "    \n",
                "    Returns:\n",
                "    --------\n",
                "    pd.DataFrame\n",
                "        DataFrame with authors as index and subreddit fractions as columns\n",
                "    \"\"\"\n",
                "    # Count posts per author per subreddit\n",
                "    author_subreddit_counts = df.groupby(['author', 'subreddit']).size().unstack(fill_value=0)\n",
                "    \n",
                "    # Keep only the top subreddits\n",
                "    top_subs_available = [s for s in top_subreddits if s in author_subreddit_counts.columns]\n",
                "    author_subreddit_counts = author_subreddit_counts[top_subs_available]\n",
                "    \n",
                "    # Add columns for missing subreddits (if any)\n",
                "    for sub in top_subreddits:\n",
                "        if sub not in author_subreddit_counts.columns:\n",
                "            author_subreddit_counts[sub] = 0\n",
                "    \n",
                "    # Reorder columns to match the original order\n",
                "    author_subreddit_counts = author_subreddit_counts[top_subreddits]\n",
                "    \n",
                "    # Get total posts per author\n",
                "    total_posts_per_author = df.groupby('author').size()\n",
                "    \n",
                "    # Compute fractions\n",
                "    author_subreddit_fractions = author_subreddit_counts.div(total_posts_per_author, axis=0)\n",
                "    \n",
                "    # Handle any NaN values (shouldn't happen, but just in case)\n",
                "    author_subreddit_fractions = author_subreddit_fractions.fillna(0)\n",
                "    \n",
                "    return author_subreddit_fractions\n",
                "\n",
                "# Create the bag of subreddits features\n",
                "bag_of_subreddits = create_bag_of_subreddits(df_supervised, top_15_subreddits)\n",
                "\n",
                "print(f\"Bag of Subreddits shape: {bag_of_subreddits.shape}\")\n",
                "print(f\"\\nFeature names (columns): {bag_of_subreddits.columns.tolist()}\")\n",
                "print(f\"\\nSample of the feature matrix:\")\n",
                "bag_of_subreddits.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "validate-fractions",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate: fractions should sum to <= 1 for each author\n",
                "# (can be < 1 if author posts in subreddits outside top 15)\n",
                "fraction_sums = bag_of_subreddits.sum(axis=1)\n",
                "\n",
                "print(f\"Fraction sum statistics:\")\n",
                "print(f\"Min: {fraction_sums.min():.4f}\")\n",
                "print(f\"Max: {fraction_sums.max():.4f}\")\n",
                "print(f\"Mean: {fraction_sums.mean():.4f}\")\n",
                "print(f\"Std: {fraction_sums.std():.4f}\")\n",
                "\n",
                "# Distribution of fraction sums\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.hist(fraction_sums, bins=50, edgecolor='black')\n",
                "plt.xlabel('Sum of Top 15 Subreddit Fractions')\n",
                "plt.ylabel('Number of Authors')\n",
                "plt.title('Distribution of Top 15 Subreddit Activity per Author')\n",
                "plt.axvline(x=fraction_sums.mean(), color='r', linestyle='--', label=f'Mean: {fraction_sums.mean():.2f}')\n",
                "plt.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step4-header",
            "metadata": {},
            "source": [
                "## Step 4: Match with Target Labels and Prepare for Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "match-labels",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get authors that are in both the bag_of_subreddits and target_df\n",
                "common_authors = bag_of_subreddits.index.intersection(target_df['author'])\n",
                "print(f\"Authors in bag_of_subreddits: {len(bag_of_subreddits)}\")\n",
                "print(f\"Authors in target: {len(target_df)}\")\n",
                "print(f\"Common authors: {len(common_authors)}\")\n",
                "\n",
                "# Filter to only include authors with labels\n",
                "bag_of_subreddits_labeled = bag_of_subreddits.loc[common_authors].copy()\n",
                "\n",
                "# Get corresponding labels\n",
                "target_df_indexed = target_df.set_index('author')\n",
                "labels = target_df_indexed.loc[common_authors, 'gender'].values\n",
                "\n",
                "print(f\"\\nFinal feature matrix shape: {bag_of_subreddits_labeled.shape}\")\n",
                "print(f\"Labels shape: {labels.shape}\")\n",
                "print(f\"\\nLabel distribution:\")\n",
                "print(pd.Series(labels).value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step5-header",
            "metadata": {},
            "source": [
                "## Step 5: Train-Validation-Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "split-data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare X and y\n",
                "X_subreddit = bag_of_subreddits_labeled.values\n",
                "y = labels\n",
                "\n",
                "# Use the stratified split function from src.py\n",
                "X_train, X_val, X_test, y_train, y_val, y_test = stratified_split(X_subreddit, y)\n",
                "\n",
                "print(f\"Training set: {X_train.shape[0]} samples\")\n",
                "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
                "print(f\"Test set: {X_test.shape[0]} samples\")\n",
                "\n",
                "print(f\"\\nFeature dimensions: {X_train.shape[1]} (Top {TOP_N} subreddits)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step6-header",
            "metadata": {},
            "source": [
                "## Step 6: Visualize Feature Importance by Gender"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "visualize-by-gender",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare subreddit usage between genders\n",
                "bag_of_subreddits_with_labels = bag_of_subreddits_labeled.copy()\n",
                "bag_of_subreddits_with_labels['gender'] = labels\n",
                "\n",
                "# Calculate mean fraction for each gender\n",
                "gender_means = bag_of_subreddits_with_labels.groupby('gender')[top_15_subreddits].mean()\n",
                "\n",
                "# Plot comparison\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "\n",
                "# Bar plot comparison\n",
                "x = np.arange(len(top_15_subreddits))\n",
                "width = 0.35\n",
                "\n",
                "axes[0].bar(x - width/2, gender_means.loc[0], width, label='Male (0)', alpha=0.8)\n",
                "axes[0].bar(x + width/2, gender_means.loc[1], width, label='Female (1)', alpha=0.8)\n",
                "axes[0].set_xlabel('Subreddit')\n",
                "axes[0].set_ylabel('Mean Fraction of Posts')\n",
                "axes[0].set_title('Average Subreddit Activity by Gender')\n",
                "axes[0].set_xticks(x)\n",
                "axes[0].set_xticklabels(top_15_subreddits, rotation=45, ha='right')\n",
                "axes[0].legend()\n",
                "\n",
                "# Difference plot (Female - Male)\n",
                "diff = gender_means.loc[1] - gender_means.loc[0]\n",
                "colors = ['pink' if d > 0 else 'lightblue' for d in diff]\n",
                "axes[1].barh(top_15_subreddits, diff, color=colors)\n",
                "axes[1].axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
                "axes[1].set_xlabel('Difference (Female - Male)')\n",
                "axes[1].set_ylabel('Subreddit')\n",
                "axes[1].set_title('Gender Difference in Subreddit Activity\\n(Pink = More Female, Blue = More Male)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step7-header",
            "metadata": {},
            "source": [
                "## Step 7: Save Features for Model Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "save-features",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the bag of subreddits features\n",
                "np.save('./Data/bag_of_subreddits_train.npy', X_train)\n",
                "np.save('./Data/bag_of_subreddits_val.npy', X_val)\n",
                "np.save('./Data/bag_of_subreddits_test.npy', X_test)\n",
                "\n",
                "# Save labels\n",
                "np.save('./Data/y_subreddit_train.npy', y_train)\n",
                "np.save('./Data/y_subreddit_val.npy', y_val)\n",
                "np.save('./Data/y_subreddit_test.npy', y_test)\n",
                "\n",
                "# Save the feature names for reference\n",
                "np.save('./Data/top15_subreddit_names.npy', np.array(top_15_subreddits))\n",
                "\n",
                "print(\"âœ… Bag of Subreddits features saved successfully!\")\n",
                "print(f\"\\nSaved files:\")\n",
                "print(f\"  - bag_of_subreddits_train.npy: {X_train.shape}\")\n",
                "print(f\"  - bag_of_subreddits_val.npy: {X_val.shape}\")\n",
                "print(f\"  - bag_of_subreddits_test.npy: {X_test.shape}\")\n",
                "print(f\"  - y_subreddit_train.npy: {y_train.shape}\")\n",
                "print(f\"  - y_subreddit_val.npy: {y_val.shape}\")\n",
                "print(f\"  - y_subreddit_test.npy: {y_test.shape}\")\n",
                "print(f\"  - top15_subreddit_names.npy: {len(top_15_subreddits)} names\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary-header",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "In this notebook we have:\n",
                "\n",
                "1. **Identified the Top 15 subreddits** by post count\n",
                "2. **Created a Bag of Subreddits feature matrix** where each feature represents the fraction of an author's posts in a given subreddit\n",
                "3. **Matched features with target labels** (gender)\n",
                "4. **Split the data** into training, validation, and test sets using stratified sampling\n",
                "5. **Visualized gender differences** in subreddit activity patterns\n",
                "6. **Saved the features** for use in model training\n",
                "\n",
                "These features can now be:\n",
                "- Used alone for classification\n",
                "- Combined with text features (BoW, TF-IDF) to potentially improve model performance"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}