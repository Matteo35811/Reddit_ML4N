{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Sentiment Analysis (Classical)\n",
    "\n",
    "Reddit comments often carry emotional tone and thematic content. In this exercise, we explore \n",
    "sentiment analysis to enrich our understanding of text analytics. \n",
    "\n",
    "**Objectives:**\n",
    "- Use VADER (pre-trained sentiment analysis model) to classify comments as positive, negative, or neutral\n",
    "- Analyze overall sentiment distribution across all comments\n",
    "- Visualize sentiment distribution per subreddit\n",
    "- Investigate correlation between sentiment and gender\n",
    "\n",
    "**Important Note:** For sentiment analysis, we should NOT remove negation words like \"not\", \"never\", \"no\" \n",
    "as they drastically change the sentiment of a sentence. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Setup and Imports\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install required packages (run once)\n",
    "#! pip install pandas numpy matplotlib seaborn nltk scipy tqdm\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment. vader import SentimentIntensityAnalyzer\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import html\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "print(\"Setup complete!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Load Data\n",
    "\n",
    "**Important:** For sentiment analysis, we use the ORIGINAL text (not the cleaned version from Section 1).\n",
    "Negation words (not, never, no) are crucial for sentiment detection! \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the supervised dataset\n",
    "df_supervised = pd. read_csv('../data/data_supervised.csv')\n",
    "df_target = pd.read_csv('../data/target_supervised.csv')\n",
    "\n",
    "print(f\"Supervised dataset shape: {df_supervised. shape}\")\n",
    "print(f\"Target dataset shape: {df_target. shape}\")\n",
    "print(f\"\\nColumns in supervised data: {df_supervised.columns.tolist()}\")\n",
    "print(f\"Columns in target data: {df_target.columns.tolist()}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preview the data\n",
    "print(\"Sample comments:\")\n",
    "print(df_supervised.head())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Basic statistics\n",
    "print(f\"\\nUnique authors: {df_supervised['author']. nunique()}\")\n",
    "print(f\"Unique subreddits:  {df_supervised['subreddit'].nunique()}\")\n",
    "print(f\"Total comments: {len(df_supervised)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Preprocessing for Sentiment Analysis\n",
    "\n",
    "For sentiment analysis, we apply **minimal preprocessing** that preserves sentiment-bearing words. \n",
    "\n",
    "**What we KEEP:**\n",
    "- Negation words (not, never, no, etc.)\n",
    "- Punctuation (!  and ?  carry sentiment)\n",
    "- Case sensitivity (VADER uses caps for emphasis detection)\n",
    "\n",
    "**What we REMOVE:**\n",
    "- URLs\n",
    "- Reddit-specific references (r/subreddit, u/username)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_for_sentiment(text):\n",
    "    \"\"\"\n",
    "    Minimal preprocessing for sentiment analysis. \n",
    "    Preserves negation words and sentiment-bearing content.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Decode HTML entities (e.g., &amp; -> &)\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove subreddit and user references (r/...  and u/...)\n",
    "    text = re.sub(r'r/\\w+|u/\\w+', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re. sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # NOTE: We do NOT: \n",
    "    # - Remove stopwords (especially negations like 'not', 'never', 'no')\n",
    "    # - Lowercase (VADER handles case sensitivity for emphasis detection)\n",
    "    # - Remove punctuation (!  and ? carry sentiment information)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"Applying preprocessing for sentiment analysis...\")\n",
    "df_supervised['body_sentiment'] = df_supervised['body']. progress_apply(preprocess_for_sentiment)\n",
    "\n",
    "print(f\"\\nPreprocessing complete!\")\n",
    "print(f\"Empty bodies after preprocessing: {(df_supervised['body_sentiment'] == '').sum()}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Show comparison between original and preprocessed text\n",
    "print(\"Sample comparison (Original vs Preprocessed):\\n\")\n",
    "for idx in range(3):\n",
    "    original = str(df_supervised.iloc[idx]['body'])[:150]\n",
    "    processed = df_supervised.iloc[idx]['body_sentiment'][:150]\n",
    "    print(f\"--- Comment {idx + 1} ---\")\n",
    "    print(f\"Original:     {original}...\")\n",
    "    print(f\"Preprocessed: {processed}...\")\n",
    "    print()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Sentiment Analysis with VADER\n",
    "\n",
    "**VADER (Valence Aware Dictionary and sEntiment Reasoner)** is a lexicon and rule-based \n",
    "sentiment analysis tool specifically attuned to sentiments expressed in social media. \n",
    "\n",
    "VADER returns 4 scores:\n",
    "- `neg`: Negative sentiment proportion (0-1)\n",
    "- `neu`: Neutral sentiment proportion (0-1)\n",
    "- `pos`: Positive sentiment proportion (0-1)\n",
    "- `compound`: Normalized, weighted composite score (-1 to +1)\n",
    "\n",
    "**Classification thresholds (standard):**\n",
    "- Positive: compound >= 0.05\n",
    "- Negative: compound <= -0.05\n",
    "- Neutral: -0.05 < compound < 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Test VADER on sample sentences to verify it works correctly\n",
    "test_sentences = [\n",
    "    \"I love this!  It's amazing! \",\n",
    "    \"This is terrible and I hate it.\",\n",
    "    \"It's okay, nothing special.\",\n",
    "    \"I am NOT happy about this.\",      # Test negation handling\n",
    "    \"I am happy about this.\",\n",
    "    \"This is AMAZING!!! \",              # Test emphasis (caps + punctuation)\n",
    "    \"meh, whatever\"\n",
    "]\n",
    "\n",
    "print(\"VADER Test Results:\")\n",
    "print(\"-\" * 80)\n",
    "for sentence in test_sentences:\n",
    "    scores = sia.polarity_scores(sentence)\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        label = \"POSITIVE\"\n",
    "    elif compound <= -0.05:\n",
    "        label = \"NEGATIVE\"\n",
    "    else: \n",
    "        label = \"NEUTRAL\"\n",
    "    print(f\"Text: {sentence: 40s} | Compound: {compound: +.3f} | {label}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_sentiment_scores(text):\n",
    "    \"\"\"Get VADER sentiment scores for a text.\"\"\"\n",
    "    if not text or text == \"\": \n",
    "        return {'neg': 0, 'neu':  1, 'pos': 0, 'compound': 0}\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "def classify_sentiment(compound_score):\n",
    "    \"\"\"Classify sentiment based on compound score.\"\"\"\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else: \n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment analysis to all comments\n",
    "print(\"Analyzing sentiment for all comments...\")\n",
    "sentiment_scores = df_supervised['body_sentiment'].progress_apply(get_sentiment_scores)\n",
    "\n",
    "# Extract individual scores\n",
    "df_supervised['sentiment_neg'] = sentiment_scores. apply(lambda x: x['neg'])\n",
    "df_supervised['sentiment_neu'] = sentiment_scores.apply(lambda x: x['neu'])\n",
    "df_supervised['sentiment_pos'] = sentiment_scores.apply(lambda x: x['pos'])\n",
    "df_supervised['sentiment_compound'] = sentiment_scores.apply(lambda x: x['compound'])\n",
    "\n",
    "# Classify sentiment\n",
    "df_supervised['sentiment_label'] = df_supervised['sentiment_compound'].apply(classify_sentiment)\n",
    "\n",
    "print(\"\\nSentiment analysis complete!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Preview results\n",
    "print(\"Sample results:\")\n",
    "print(df_supervised[['body_sentiment', 'sentiment_compound', 'sentiment_label']]. head(10))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Overall Sentiment Distribution (Task 1b)\n",
    "\n",
    "**Question:** What is the overall sentiment distribution across all comments?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate sentiment distribution\n",
    "sentiment_counts = df_supervised['sentiment_label'].value_counts()\n",
    "sentiment_percentages = df_supervised['sentiment_label'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"OVERALL SENTIMENT DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "for label in ['positive', 'neutral', 'negative']:\n",
    "    count = sentiment_counts. get(label, 0)\n",
    "    pct = sentiment_percentages.get(label, 0)\n",
    "    print(f\"{label. capitalize():10s}: {count:>7,} comments ({pct: >5.2f}%)\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Total':10s}: {len(df_supervised):>7,} comments\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compound score statistics\n",
    "print(\"\\nCompound Score Statistics:\")\n",
    "print(df_supervised['sentiment_compound'].describe())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualization of overall sentiment distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Define colors\n",
    "colors = {'positive': '#2ecc71', 'neutral':  '#3498db', 'negative': '#e74c3c'}\n",
    "order = ['positive', 'neutral', 'negative']\n",
    "\n",
    "# 1. Bar chart of sentiment counts\n",
    "ax1 = axes[0]\n",
    "bars = ax1.bar(order, [sentiment_counts. get(s, 0) for s in order],\n",
    "               color=[colors[s] for s in order], edgecolor='black', linewidth=1. 2)\n",
    "ax1.set_xlabel('Sentiment', fontsize=12)\n",
    "ax1.set_ylabel('Number of Comments', fontsize=12)\n",
    "ax1.set_title('Sentiment Distribution (Counts)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, label in zip(bars, order):\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{int(height):,}',\n",
    "                 xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                 ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 2. Pie chart\n",
    "ax2 = axes[1]\n",
    "sizes = [sentiment_counts.get(s, 0) for s in order]\n",
    "explode = (0.02, 0.02, 0.02)\n",
    "ax2.pie(sizes, labels=[s.capitalize() for s in order], autopct='%1.1f%%',\n",
    "        colors=[colors[s] for s in order], explode=explode,\n",
    "        startangle=90, textprops={'fontsize': 11})\n",
    "ax2.set_title('Sentiment Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Histogram of compound scores\n",
    "ax3 = axes[2]\n",
    "ax3.hist(df_supervised['sentiment_compound'], bins=50, color='steelblue',\n",
    "         edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(x=0.05, color='green', linestyle='--', linewidth=2, label='Positive threshold (0.05)')\n",
    "ax3.axvline(x=-0.05, color='red', linestyle='--', linewidth=2, label='Negative threshold (-0.05)')\n",
    "ax3.set_xlabel('Compound Score', fontsize=12)\n",
    "ax3.set_ylabel('Frequency', fontsize=12)\n",
    "ax3.set_title('Distribution of Compound Scores', fontsize=14, fontweight='bold')\n",
    "ax3.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4. 1_sentiment_overall_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Sentiment Distribution per Subreddit (Task 1c)\n",
    "\n",
    "**Question:** Visualize sentiment distribution per subreddit using bar charts or heatmaps.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate sentiment distribution per subreddit\n",
    "subreddit_sentiment = df_supervised.groupby(['subreddit', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate percentages\n",
    "subreddit_sentiment_pct = subreddit_sentiment.div(subreddit_sentiment.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Reorder columns if they exist\n",
    "cols_order = ['positive', 'neutral', 'negative']\n",
    "cols_present = [c for c in cols_order if c in subreddit_sentiment_pct.columns]\n",
    "subreddit_sentiment_pct = subreddit_sentiment_pct[cols_present]\n",
    "\n",
    "# Get top 20 subreddits by comment count\n",
    "top_subreddits = df_supervised['subreddit'].value_counts().head(20).index.tolist()\n",
    "\n",
    "print(f\"Total unique subreddits: {df_supervised['subreddit'].nunique()}\")\n",
    "print(f\"\\nTop 20 subreddits by comment count:\")\n",
    "print(df_supervised['subreddit'].value_counts().head(20))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Average compound score per subreddit\n",
    "subreddit_compound = df_supervised.groupby('subreddit')['sentiment_compound'].agg(['mean', 'std', 'count'])\n",
    "subreddit_compound = subreddit_compound.sort_values('mean', ascending=False)\n",
    "\n",
    "# Filter subreddits with at least 100 comments for reliability\n",
    "subreddit_compound_filtered = subreddit_compound[subreddit_compound['count'] >= 100]\n",
    "\n",
    "print(\"\\nMost POSITIVE Subreddits (min 100 comments):\")\n",
    "print(subreddit_compound_filtered.head(10))\n",
    "\n",
    "print(\"\\nMost NEGATIVE Subreddits (min 100 comments):\")\n",
    "print(subreddit_compound_filtered.tail(10))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6.1 Stacked Bar Chart - Sentiment by Subreddit\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Stacked horizontal bar chart for top 20 subreddits\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Filter to top subreddits\n",
    "plot_data = subreddit_sentiment_pct.loc[top_subreddits][cols_present]\n",
    "\n",
    "# Create stacked bar chart\n",
    "plot_data.plot(kind='barh', stacked=True, ax=ax,\n",
    "               color=[colors. get(c, 'gray') for c in cols_present],\n",
    "               edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Percentage (%)', fontsize=12)\n",
    "ax.set_ylabel('Subreddit', fontsize=12)\n",
    "ax.set_title('Sentiment Distribution by Subreddit (Top 20 by Comment Count)', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Sentiment', loc='lower right', fontsize=10)\n",
    "ax.set_xlim(0, 100)\n",
    "ax.xaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.2_sentiment_by_subreddit_bar.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.2 Heatmap - Sentiment Distribution\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Heatmap of sentiment distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "# Prepare heatmap data\n",
    "heatmap_data = subreddit_sentiment_pct.loc[top_subreddits][cols_present]\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(heatmap_data,\n",
    "            annot=True,\n",
    "            fmt='.1f',\n",
    "            cmap='RdYlGn',\n",
    "            center=50,\n",
    "            ax=ax,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={'label': 'Percentage (%)'})\n",
    "\n",
    "ax.set_xlabel('Sentiment', fontsize=12)\n",
    "ax.set_ylabel('Subreddit', fontsize=12)\n",
    "ax.set_title('Sentiment Distribution Heatmap (Top 20 Subreddits)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.3_sentiment_by_subreddit_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.3 Most Positive and Negative Subreddits\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Bar chart comparing most positive vs most negative subreddits\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top 10 most positive subreddits\n",
    "top_positive = subreddit_compound_filtered.head(10)\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.barh(top_positive. index, top_positive['mean'], color='#2ecc71', edgecolor='black')\n",
    "ax1.set_xlabel('Average Compound Score', fontsize=12)\n",
    "ax1.set_ylabel('Subreddit', fontsize=12)\n",
    "ax1.set_title('Top 10 Most POSITIVE Subreddits', fontsize=14, fontweight='bold')\n",
    "ax1.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    width = bar.get_width()\n",
    "    ax1.annotate(f'{width:.3f}',\n",
    "                 xy=(width, bar.get_y() + bar.get_height()/2),\n",
    "                 ha='left', va='center', fontsize=9, xytext=(5, 0),\n",
    "                 textcoords='offset points')\n",
    "\n",
    "# Top 10 most negative subreddits\n",
    "top_negative = subreddit_compound_filtered.tail(10)\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.barh(top_negative. index, top_negative['mean'], color='#e74c3c', edgecolor='black')\n",
    "ax2.set_xlabel('Average Compound Score', fontsize=12)\n",
    "ax2.set_ylabel('Subreddit', fontsize=12)\n",
    "ax2.set_title('Top 10 Most NEGATIVE Subreddits', fontsize=14, fontweight='bold')\n",
    "ax2.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars2:\n",
    "    width = bar.get_width()\n",
    "    ax2.annotate(f'{width:.3f}',\n",
    "                 xy=(width, bar.get_y() + bar.get_height()/2),\n",
    "                 ha='right' if width < 0 else 'left', va='center', fontsize=9,\n",
    "                 xytext=(-5 if width < 0 else 5, 0),\n",
    "                 textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.4_sentiment_extreme_subreddits.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6.4 Grouped Bar Chart - Sentiment Counts per Subreddit\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Grouped bar chart showing actual counts\n",
    "fig, ax = plt. subplots(figsize=(14, 8))\n",
    "\n",
    "# Get top 15 subreddits for cleaner visualization\n",
    "top_15_subs = df_supervised['subreddit'].value_counts().head(15).index.tolist()\n",
    "plot_counts = subreddit_sentiment. loc[top_15_subs][cols_present]\n",
    "\n",
    "# Set up bar positions\n",
    "x = np.arange(len(top_15_subs))\n",
    "width = 0.25\n",
    "\n",
    "# Create bars\n",
    "bars1 = ax.bar(x - width, plot_counts['positive'], width, label='Positive', color='#2ecc71', edgecolor='black')\n",
    "bars2 = ax.bar(x, plot_counts['neutral'], width, label='Neutral', color='#3498db', edgecolor='black')\n",
    "bars3 = ax.bar(x + width, plot_counts['negative'], width, label='Negative', color='#e74c3c', edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Subreddit', fontsize=12)\n",
    "ax.set_ylabel('Number of Comments', fontsize=12)\n",
    "ax.set_title('Sentiment Counts by Subreddit (Top 15)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(top_15_subs, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.5_sentiment_counts_by_subreddit.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Sentiment Correlation with Gender (Task 1d)\n",
    "\n",
    "**Question:** Does sentiment correlate with gender?  Do male or female users tend to post \n",
    "more positive or negative comments?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check the structure of the target file\n",
    "print(\"Target file structure:\")\n",
    "print(df_target.head())\n",
    "print(f\"\\nTarget columns: {df_target.columns.tolist()}\")\n",
    "print(f\"Target shape: {df_target.shape}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create author-gender mapping\n",
    "if 'author' in df_target.columns:\n",
    "    # If target has author column\n",
    "    author_gender_map = df_target. set_index('author')['gender'].to_dict()\n",
    "    print(\"Using 'author' column from target file for mapping\")\n",
    "else:\n",
    "    # If target is aligned with unique authors\n",
    "    unique_authors = df_supervised. drop_duplicates('author')['author'].tolist()\n",
    "    \n",
    "    if len(unique_authors) == len(df_target):\n",
    "        author_gender_map = dict(zip(unique_authors, df_target['gender']))\n",
    "        print(\"Mapping based on author order alignment\")\n",
    "    else:\n",
    "        # Try sorting alphabetically\n",
    "        unique_authors_sorted = sorted(df_supervised['author'].unique())\n",
    "        author_gender_map = dict(zip(unique_authors_sorted, df_target['gender']))\n",
    "        print(\"Mapping based on alphabetically sorted authors\")\n",
    "\n",
    "print(f\"\\nTotal authors mapped: {len(author_gender_map)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Apply gender mapping to dataframe\n",
    "df_supervised['gender'] = df_supervised['author'].map(author_gender_map)\n",
    "\n",
    "# Create readable labels (0=Male, 1=Female as per project description)\n",
    "df_supervised['gender_label'] = df_supervised['gender'].map({0: 'Male', 1: 'Female'})\n",
    "\n",
    "# Check mapping success\n",
    "print(\"Gender Mapping Results:\")\n",
    "print(f\"Comments with gender info: {df_supervised['gender']. notna().sum():,}\")\n",
    "print(f\"Comments without gender info: {df_supervised['gender'].isna().sum():,}\")\n",
    "\n",
    "print(f\"\\nGender distribution in comments:\")\n",
    "print(df_supervised['gender_label'].value_counts())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate sentiment distribution by gender\n",
    "gender_sentiment = df_supervised.groupby(['gender_label', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "gender_sentiment_pct = gender_sentiment.div(gender_sentiment.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(\"\\nSentiment Distribution by Gender (Counts):\")\n",
    "print(gender_sentiment)\n",
    "\n",
    "print(\"\\nSentiment Distribution by Gender (Percentages):\")\n",
    "print(gender_sentiment_pct. round(2))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.1 Statistical Analysis - Gender vs Sentiment\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract compound scores by gender\n",
    "male_compound = df_supervised[df_supervised['gender_label'] == 'Male']['sentiment_compound']. dropna()\n",
    "female_compound = df_supervised[df_supervised['gender_label'] == 'Female']['sentiment_compound'].dropna()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STATISTICAL ANALYSIS:  Sentiment by Gender\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n--- MALE Users ---\")\n",
    "print(f\"  Number of comments: {len(male_compound):,}\")\n",
    "print(f\"  Mean compound score: {male_compound. mean():.4f}\")\n",
    "print(f\"  Std deviation: {male_compound.std():.4f}\")\n",
    "print(f\"  Median:  {male_compound.median():.4f}\")\n",
    "print(f\"  Min: {male_compound. min():.4f}\")\n",
    "print(f\"  Max: {male_compound.max():.4f}\")\n",
    "\n",
    "print(f\"\\n--- FEMALE Users ---\")\n",
    "print(f\"  Number of comments: {len(female_compound):,}\")\n",
    "print(f\"  Mean compound score: {female_compound.mean():.4f}\")\n",
    "print(f\"  Std deviation: {female_compound.std():.4f}\")\n",
    "print(f\"  Median: {female_compound. median():.4f}\")\n",
    "print(f\"  Min: {female_compound.min():.4f}\")\n",
    "print(f\"  Max: {female_compound.max():.4f}\")\n",
    "\n",
    "print(f\"\\n--- DIFFERENCE ---\")\n",
    "mean_diff = female_compound.mean() - male_compound.mean()\n",
    "print(f\"  Difference in means (Female - Male): {mean_diff:.4f}\")\n",
    "if mean_diff > 0:\n",
    "    print(f\"  â†’ Female users are slightly MORE POSITIVE on average\")\n",
    "else:\n",
    "    print(f\"  â†’ Male users are slightly MORE POSITIVE on average\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Statistical Tests\n",
    "\n",
    "# 1. Mann-Whitney U Test (non-parametric, good for non-normal distributions)\n",
    "statistic_mw, p_value_mw = stats.mannwhitneyu(male_compound, female_compound, alternative='two-sided')\n",
    "\n",
    "# 2. Independent t-test (parametric)\n",
    "statistic_t, p_value_t = stats.ttest_ind(male_compound, female_compound)\n",
    "\n",
    "# 3. Effect size (Cohen's d)\n",
    "pooled_std = np.sqrt(((len(male_compound)-1)*male_compound.std()**2 +\n",
    "                       (len(female_compound)-1)*female_compound.std()**2) /\n",
    "                      (len(male_compound) + len(female_compound) - 2))\n",
    "cohens_d = (female_compound.mean() - male_compound.mean()) / pooled_std\n",
    "\n",
    "print(\"\\n--- STATISTICAL TESTS ---\")\n",
    "print(f\"\\n1. Mann-Whitney U Test (non-parametric):\")\n",
    "print(f\"   Statistic: {statistic_mw: ,.0f}\")\n",
    "print(f\"   P-value: {p_value_mw:.6f}\")\n",
    "print(f\"   Significant at Î±=0.05: {'YES' if p_value_mw < 0.05 else 'NO'}\")\n",
    "print(f\"   Significant at Î±=0.01: {'YES' if p_value_mw < 0.01 else 'NO'}\")\n",
    "\n",
    "print(f\"\\n2. Independent t-test (parametric):\")\n",
    "print(f\"   Statistic: {statistic_t:.4f}\")\n",
    "print(f\"   P-value: {p_value_t:.6f}\")\n",
    "print(f\"   Significant at Î±=0.05: {'YES' if p_value_t < 0.05 else 'NO'}\")\n",
    "\n",
    "print(f\"\\n3. Effect Size (Cohen's d): {cohens_d:.4f}\")\n",
    "if abs(cohens_d) < 0.2:\n",
    "    effect_interpretation = \"negligible\"\n",
    "elif abs(cohens_d) < 0.5:\n",
    "    effect_interpretation = \"small\"\n",
    "elif abs(cohens_d) < 0.8:\n",
    "    effect_interpretation = \"medium\"\n",
    "else:\n",
    "    effect_interpretation = \"large\"\n",
    "print(f\"   Interpretation: {effect_interpretation} effect\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.2 Visualizations - Gender vs Sentiment\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Grouped Bar Chart - Sentiment percentages by gender\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "sentiments = ['positive', 'neutral', 'negative']\n",
    "\n",
    "male_pct = [gender_sentiment_pct.loc['Male', s] if s in gender_sentiment_pct.columns else 0 for s in sentiments]\n",
    "female_pct = [gender_sentiment_pct. loc['Female', s] if s in gender_sentiment_pct. columns else 0 for s in sentiments]\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, male_pct, width, label='Male', color='#3498db', edgecolor='black')\n",
    "bars2 = ax1.bar(x + width/2, female_pct, width, label='Female', color='#e91e63', edgecolor='black')\n",
    "\n",
    "ax1.set_xlabel('Sentiment', fontsize=12)\n",
    "ax1.set_ylabel('Percentage (%)', fontsize=12)\n",
    "ax1.set_title('Sentiment Distribution by Gender', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([s.capitalize() for s in sentiments])\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, max(max(male_pct), max(female_pct)) * 1.15)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.1f}%', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                 ha='center', va='bottom', fontsize=9)\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.1f}%', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                 ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Box Plot - Compound score distribution\n",
    "ax2 = axes[0, 1]\n",
    "box_data = [male_compound, female_compound]\n",
    "bp = ax2.boxplot(box_data, labels=['Male', 'Female'], patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "bp['boxes'][0].set_facecolor('#3498db')\n",
    "bp['boxes'][1].set_facecolor('#e91e63')\n",
    "for median in bp['medians']:\n",
    "    median.set_color('black')\n",
    "    median.set_linewidth(2)\n",
    "\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Compound Score', fontsize=12)\n",
    "ax2.set_title('Compound Score Distribution by Gender', fontsize=14, fontweight='bold')\n",
    "ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax2.yaxis.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# 3. Violin Plot - Detailed distribution shape\n",
    "ax3 = axes[1, 0]\n",
    "parts = ax3.violinplot([male_compound, female_compound], positions=[1, 2], showmeans=True, showmedians=True)\n",
    "\n",
    "# Color violins\n",
    "colors_violin = ['#3498db', '#e91e63']\n",
    "for i, pc in enumerate(parts['bodies']):\n",
    "    pc.set_facecolor(colors_violin[i])\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "ax3.set_xticks([1, 2])\n",
    "ax3.set_xticklabels(['Male', 'Female'])\n",
    "ax3.set_xlabel('Gender', fontsize=12)\n",
    "ax3.set_ylabel('Compound Score', fontsize=12)\n",
    "ax3.set_title('Sentiment Distribution (Violin Plot)', fontsize=14, fontweight='bold')\n",
    "ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 4. KDE Plot - Density comparison\n",
    "ax4 = axes[1, 1]\n",
    "sns.kdeplot(data=male_compound, ax=ax4, label=f'Male (Î¼={male_compound.mean():.3f})',\n",
    "            color='#3498db', fill=True, alpha=0.3, linewidth=2)\n",
    "sns.kdeplot(data=female_compound, ax=ax4, label=f'Female (Î¼={female_compound. mean():.3f})',\n",
    "            color='#e91e63', fill=True, alpha=0.3, linewidth=2)\n",
    "\n",
    "# Add mean lines\n",
    "ax4.axvline(x=male_compound. mean(), color='#3498db', linestyle='--', linewidth=2, alpha=0.8)\n",
    "ax4.axvline(x=female_compound.mean(), color='#e91e63', linestyle='--', linewidth=2, alpha=0.8)\n",
    "\n",
    "ax4.set_xlabel('Compound Score', fontsize=12)\n",
    "ax4.set_ylabel('Density', fontsize=12)\n",
    "ax4.set_title('Compound Score Density by Gender', fontsize=14, fontweight='bold')\n",
    "ax4.legend(loc='upper right')\n",
    "\n",
    "# Add p-value annotation\n",
    "ax4.text(0.02, 0.98, f'Mann-Whitney p={p_value_mw:.4f}\\nCohen\\'s d={cohens_d:.4f} ({effect_interpretation})',\n",
    "         transform=ax4.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.6_sentiment_by_gender_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7.3 User-Level Analysis\n",
    "\n",
    "Aggregate sentiment per user (instead of per comment) for a more robust analysis. \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aggregate by user - average sentiment per user\n",
    "user_sentiment = df_supervised.groupby(['author', 'gender_label']).agg({\n",
    "    'sentiment_compound': ['mean', 'std', 'count'],\n",
    "    'sentiment_pos': 'mean',\n",
    "    'sentiment_neg': 'mean',\n",
    "    'sentiment_neu': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "user_sentiment.columns = ['author', 'gender_label', 'compound_mean', 'compound_std',\n",
    "                          'num_comments', 'pos_mean', 'neg_mean', 'neu_mean']\n",
    "\n",
    "print(\"User-level Sentiment Statistics:\")\n",
    "print(user_sentiment. groupby('gender_label').agg({\n",
    "    'compound_mean': ['mean', 'std', 'median'],\n",
    "    'num_comments': ['mean', 'sum']\n",
    "}).round(4))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# User-level statistical test\n",
    "male_users = user_sentiment[user_sentiment['gender_label'] == 'Male']['compound_mean'].dropna()\n",
    "female_users = user_sentiment[user_sentiment['gender_label'] == 'Female']['compound_mean']. dropna()\n",
    "\n",
    "stat_user, p_user = stats.mannwhitneyu(male_users, female_users, alternative='two-sided')\n",
    "\n",
    "print(f\"\\n--- USER-LEVEL ANALYSIS ---\")\n",
    "print(f\"Male users: n={len(male_users)}, mean={male_users.mean():.4f}\")\n",
    "print(f\"Female users:  n={len(female_users)}, mean={female_users.mean():.4f}\")\n",
    "print(f\"Mann-Whitney U p-value: {p_user:. 6f}\")\n",
    "print(f\"Significant at Î±=0.05: {'YES' if p_user < 0.05 else 'NO'}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# User-level visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.kdeplot(data=male_users, ax=ax, label=f'Male (n={len(male_users)}, Î¼={male_users. mean():.3f})',\n",
    "            color='#3498db', fill=True, alpha=0.3, linewidth=2)\n",
    "sns.kdeplot(data=female_users, ax=ax, label=f'Female (n={len(female_users)}, Î¼={female_users.mean():.3f})',\n",
    "            color='#e91e63', fill=True, alpha=0.3, linewidth=2)\n",
    "\n",
    "ax.axvline(x=male_users.mean(), color='#3498db', linestyle='--', linewidth=2)\n",
    "ax.axvline(x=female_users.mean(), color='#e91e63', linestyle='--', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Average Compound Score per User', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('User-Level Average Sentiment by Gender', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "ax.text(0.02, 0.98, f'Mann-Whitney p={p_user:.4f}',\n",
    "        transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.7_sentiment_by_gender_user_level.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7.4 Sentiment by Gender and Subreddit (Interaction Analysis)\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze if gender differences vary across subreddits\n",
    "gender_subreddit_sentiment = df_supervised.groupby(['subreddit', 'gender_label'])['sentiment_compound'].mean().unstack()\n",
    "\n",
    "# Filter to subreddits with enough data from both genders\n",
    "min_comments_per_gender = 50\n",
    "gender_counts = df_supervised. groupby(['subreddit', 'gender_label']).size().unstack(fill_value=0)\n",
    "\n",
    "# Check which columns exist\n",
    "if 'Male' in gender_counts.columns and 'Female' in gender_counts.columns:\n",
    "    valid_subreddits = gender_counts[(gender_counts['Male'] >= min_comments_per_gender) &\n",
    "                                      (gender_counts['Female'] >= min_comments_per_gender)].index\n",
    "\n",
    "    gender_subreddit_filtered = gender_subreddit_sentiment. loc[valid_subreddits]. copy()\n",
    "    gender_subreddit_filtered['difference'] = gender_subreddit_filtered['Female'] - gender_subreddit_filtered['Male']\n",
    "    gender_subreddit_filtered = gender_subreddit_filtered. sort_values('difference')\n",
    "\n",
    "    print(f\"Subreddits with >= {min_comments_per_gender} comments from each gender:  {len(valid_subreddits)}\")\n",
    "    print(\"\\nSubreddits where FEMALES are more positive than males:\")\n",
    "    print(gender_subreddit_filtered[gender_subreddit_filtered['difference'] > 0]. tail(10))\n",
    "    print(\"\\nSubreddits where MALES are more positive than females:\")\n",
    "    print(gender_subreddit_filtered[gender_subreddit_filtered['difference'] < 0].head(10))\n",
    "else:\n",
    "    print(\"Warning:  Missing gender data in some subreddits\")\n",
    "    gender_subreddit_filtered = None\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize gender differences across subreddits\n",
    "if gender_subreddit_filtered is not None and len(gender_subreddit_filtered) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Take top 10 from each direction\n",
    "    n_show = min(10, len(gender_subreddit_filtered) // 2)\n",
    "    if n_show > 0:\n",
    "        top_female_positive = gender_subreddit_filtered.tail(n_show)\n",
    "        top_male_positive = gender_subreddit_filtered.head(n_show)\n",
    "        plot_df = pd.concat([top_male_positive, top_female_positive])\n",
    "\n",
    "        colors_diff = ['#e91e63' if x > 0 else '#3498db' for x in plot_df['difference']]\n",
    "        ax.barh(plot_df. index, plot_df['difference'], color=colors_diff, edgecolor='black')\n",
    "\n",
    "        ax.axvline(x=0, color='black', linewidth=1)\n",
    "        ax.set_xlabel('Sentiment Difference (Female - Male)', fontsize=12)\n",
    "        ax.set_ylabel('Subreddit', fontsize=12)\n",
    "        ax.set_title('Gender Sentiment Difference by Subreddit', fontsize=14, fontweight='bold')\n",
    "\n",
    "        # Add legend\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [Patch(facecolor='#e91e63', label='Females more positive'),\n",
    "                           Patch(facecolor='#3498db', label='Males more positive')]\n",
    "        ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('4.8_sentiment_gender_difference_by_subreddit.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Not enough data for subreddit-gender interaction plot\")\n",
    "else:\n",
    "    print(\"Skipping subreddit-gender interaction plot due to missing data\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Summary and Conclusions\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SECTION 4 - SENTIMENT ANALYSIS:  SUMMARY OF FINDINGS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nðŸ“Š TASK 1a - PREPROCESSING:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Used MINIMAL preprocessing for sentiment analysis\")\n",
    "print(\"â€¢ PRESERVED negation words (not, never, no) - crucial for sentiment!\")\n",
    "print(\"â€¢ PRESERVED punctuation (!  ?) and case sensitivity\")\n",
    "print(\"â€¢ REMOVED only URLs and Reddit-specific references (r/, u/)\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ TASK 1b - OVERALL SENTIMENT DISTRIBUTION:\")\n",
    "print(\"-\" * 50)\n",
    "for label in ['positive', 'neutral', 'negative']:\n",
    "    pct = sentiment_percentages. get(label, 0)\n",
    "    count = sentiment_counts.get(label, 0)\n",
    "    print(f\"â€¢ {label. capitalize():10s}:  {count:>7,} comments ({pct: >5.1f}%)\")\n",
    "\n",
    "print(\"\\nðŸ—‚ï¸ TASK 1c - SENTIMENT PER SUBREDDIT:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ Analyzed {df_supervised['subreddit'].nunique()} unique subreddits\")\n",
    "print(f\"â€¢ Most positive subreddit: {subreddit_compound_filtered.index[0]} (mean={subreddit_compound_filtered. iloc[0]['mean']:.3f})\")\n",
    "print(f\"â€¢ Most negative subreddit: {subreddit_compound_filtered.index[-1]} (mean={subreddit_compound_filtered.iloc[-1]['mean']:.3f})\")\n",
    "print(\"â€¢ Visualizations:  stacked bar chart, heatmap, extreme subreddits comparison\")\n",
    "\n",
    "print(\"\\nðŸ‘« TASK 1d - SENTIMENT vs GENDER:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ Male comments: n={len(male_compound):,}, mean={male_compound. mean():.4f}\")\n",
    "print(f\"â€¢ Female comments: n={len(female_compound):,}, mean={female_compound.mean():.4f}\")\n",
    "print(f\"â€¢ Difference (Female - Male): {mean_diff: +.4f}\")\n",
    "\n",
    "if mean_diff > 0:\n",
    "    print(\"â€¢ Finding:  Female users post SLIGHTLY MORE POSITIVE comments\")\n",
    "else:\n",
    "    print(\"â€¢ Finding: Male users post SLIGHTLY MORE POSITIVE comments\")\n",
    "\n",
    "print(f\"\\nâ€¢ Statistical Tests:\")\n",
    "print(f\"  - Mann-Whitney U p-value: {p_value_mw:.6f}\")\n",
    "print(f\"  - Significant at Î±=0.05: {'YES' if p_value_mw < 0.05 else 'NO'}\")\n",
    "print(f\"  - Effect size (Cohen's d): {cohens_d:.4f} ({effect_interpretation})\")\n",
    "\n",
    "print(\"\\nðŸ“ FILES GENERATED:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ 4.1_sentiment_overall_distribution.png\")\n",
    "print(\"â€¢ 4.2_sentiment_by_subreddit_bar. png\")\n",
    "print(\"â€¢ 4.3_sentiment_by_subreddit_heatmap.png\")\n",
    "print(\"â€¢ 4.4_sentiment_extreme_subreddits.png\")\n",
    "print(\"â€¢ 4.5_sentiment_counts_by_subreddit.png\")\n",
    "print(\"â€¢ 4.6_sentiment_by_gender_analysis.png\")\n",
    "print(\"â€¢ 4.7_sentiment_by_gender_user_level.png\")\n",
    "print(\"â€¢ 4.8_sentiment_gender_difference_by_subreddit.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Save Results for Integration with Section 2\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save comment-level sentiment features\n",
    "sentiment_features = df_supervised[['author', 'subreddit', 'body',\n",
    "                                     'sentiment_compound', 'sentiment_pos',\n",
    "                                     'sentiment_neg', 'sentiment_neu',\n",
    "                                     'sentiment_label', 'gender', 'gender_label']].copy()\n",
    "sentiment_features.to_csv('sentiment_features_comments.csv', index=False)\n",
    "print(\"âœ“ Saved:  sentiment_features_comments.csv\")\n",
    "\n",
    "# Save user-level aggregated sentiment\n",
    "user_sentiment. to_csv('sentiment_features_users.csv', index=False)\n",
    "print(\"âœ“ Saved: sentiment_features_users. csv\")\n",
    "\n",
    "# Save subreddit-level sentiment summary\n",
    "subreddit_sentiment_summary = pd.DataFrame({\n",
    "    'subreddit': subreddit_compound_filtered.index,\n",
    "    'mean_compound': subreddit_compound_filtered['mean'],\n",
    "    'std_compound': subreddit_compound_filtered['std'],\n",
    "    'num_comments': subreddit_compound_filtered['count']\n",
    "})\n",
    "subreddit_sentiment_summary.to_csv('sentiment_by_subreddit. csv', index=False)\n",
    "print(\"âœ“ Saved: sentiment_by_subreddit.csv\")\n",
    "\n",
    "print(\"\\nâœ… All files saved successfully!\")\n",
    "print(\"\\nThese files can be used in Section 2 (Integration Challenge)\")\n",
    "print(\"to add sentiment features to the gender classification pipeline.\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
