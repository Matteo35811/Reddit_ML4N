{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4 - Sentiment Analysis (Classical)\n",
    "\n",
    "Reddit comments often carry emotional tone and thematic content. In this exercise, we explore sentiment analysis to enrich our understanding of text analytics.\n",
    "\n",
    "**Objectives:**\n",
    "- Use VADER (pre-trained sentiment analysis model) to classify comments as positive, negative, or neutral\n",
    "- Analyze overall sentiment distribution\n",
    "- Visualize sentiment distribution per subreddit\n",
    "- Investigate correlation between sentiment and gender"
   ]
  },
  {
   "cell_type":  "markdown",
   "metadata":  {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy matplotlib seaborn nltk scipy"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib. pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment. vader import SentimentIntensityAnalyzer\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the supervised dataset\n",
    "# Note: Using ORIGINAL body text, not the cleaned version!\n",
    "# For sentiment analysis, we need the original text with stopwords intact\n",
    "\n",
    "df_supervised = pd.read_csv('../data/data_supervised.csv')\n",
    "df_target = pd.read_csv('../data/target_supervised.csv')\n",
    "\n",
    "print(f\"Supervised dataset shape: {df_supervised. shape}\")\n",
    "print(f\"Target dataset shape: {df_target.shape}\")\n",
    "print(f\"\\nColumns in supervised data: {df_supervised.columns.tolist()}\")\n",
    "print(f\"Columns in target data: {df_target.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "print(\"Sample comments:\")\n",
    "df_supervised.head()"
   ]
  },
  {
   "cell_type":  "markdown",
   "metadata":  {},
   "source": [
    "## 2. Preprocessing for Sentiment Analysis\n",
    "\n",
    "**Important Note:** For sentiment analysis, we should NOT remove negation words like \"not\", \"never\", \"no\" as they drastically change the sentiment of a sentence.\n",
    "\n",
    "Example:\n",
    "- \"I am happy\" → Positive\n",
    "- \"I am NOT happy\" → Negative (if we remove \"not\", we lose this information! )\n",
    "\n",
    "We apply minimal preprocessing that preserves sentiment-bearing words."
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import re\n",
    "\n",
    "def preprocess_for_sentiment(text):\n",
    "    \"\"\"\n",
    "    Minimal preprocessing for sentiment analysis.\n",
    "    Preserves negation words and sentiment-bearing content.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Decode HTML entities (e.g., &amp; -> &)\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove subreddit and user references (r/...  and u/... )\n",
    "    text = re.sub(r'r/\\w+|u/\\w+', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # NOTE: We do NOT:\n",
    "    # - Remove stopwords (especially negations like 'not', 'never', 'no')\n",
    "    # - Lowercase (VADER handles case sensitivity for emphasis detection)\n",
    "    # - Remove punctuation (!  and ?  carry sentiment information)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df_supervised['body_sentiment'] = df_supervised['body']. apply(preprocess_for_sentiment)\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(f\"Empty bodies after preprocessing: {(df_supervised['body_sentiment'] == '').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show comparison between original and preprocessed text\n",
    "comparison_df = df_supervised[['body', 'body_sentiment']].head(5)\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    print(f\"--- Comment {idx} ---\")\n",
    "    print(f\"Original: {row['body'][:200]}...\" if len(str(row['body'])) > 200 else f\"Original: {row['body']}\")\n",
    "    print(f\"Preprocessed: {row['body_sentiment'][:200]}...\" if len(row['body_sentiment']) > 200 else f\"Preprocessed:  {row['body_sentiment']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis with VADER\n",
    "\n",
    "**VADER (Valence Aware Dictionary and sEntiment Reasoner)** is a lexicon and rule-based sentiment analysis tool specifically attuned to sentiments expressed in social media.\n",
    "\n",
    "VADER returns 4 scores:\n",
    "- `neg`: Negative sentiment proportion\n",
    "- `neu`: Neutral sentiment proportion  \n",
    "- `pos`: Positive sentiment proportion\n",
    "- `compound`: Normalized, weighted composite score (-1 to +1)\n",
    "\n",
    "Classification thresholds (standard):\n",
    "- Positive: compound >= 0.05\n",
    "- Negative: compound <= -0.05\n",
    "- Neutral: -0.05 < compound < 0.05"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Test VADER on sample sentences\n",
    "test_sentences = [\n",
    "    \"I love this!  It's amazing!\",\n",
    "    \"This is terrible and I hate it.\",\n",
    "    \"It's okay, nothing special.\",\n",
    "    \"I am NOT happy about this.\",  # Test negation handling\n",
    "    \"I am happy about this.\"\n",
    "]\n",
    "\n",
    "print(\"VADER Test Results:\")\n",
    "print(\"-\" * 80)\n",
    "for sentence in test_sentences:\n",
    "    scores = sia.polarity_scores(sentence)\n",
    "    print(f\"Text: {sentence}\")\n",
    "    print(f\"Scores: {scores}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    \"\"\"Get VADER sentiment scores for a text.\"\"\"\n",
    "    if not text or text == \"\":\n",
    "        return {'neg': 0, 'neu': 1, 'pos': 0, 'compound': 0}\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "def classify_sentiment(compound_score):\n",
    "    \"\"\"Classify sentiment based on compound score.\"\"\"\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment analysis to all comments\n",
    "print(\"Analyzing sentiment for all comments... \")\n",
    "sentiment_scores = df_supervised['body_sentiment'].progress_apply(get_sentiment_scores)\n",
    "\n",
    "# Extract individual scores\n",
    "df_supervised['sentiment_neg'] = sentiment_scores. apply(lambda x: x['neg'])\n",
    "df_supervised['sentiment_neu'] = sentiment_scores.apply(lambda x: x['neu'])\n",
    "df_supervised['sentiment_pos'] = sentiment_scores. apply(lambda x: x['pos'])\n",
    "df_supervised['sentiment_compound'] = sentiment_scores.apply(lambda x: x['compound'])\n",
    "\n",
    "# Classify sentiment\n",
    "df_supervised['sentiment_label'] = df_supervised['sentiment_compound'].apply(classify_sentiment)\n",
    "\n",
    "print(\"\\nSentiment analysis complete!\")"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview results\n",
    "df_supervised[['body_sentiment', 'sentiment_compound', 'sentiment_label']]. head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Overall Sentiment Distribution (Task 1b)\n",
    "\n",
    "What is the overall sentiment distribution across all comments?"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sentiment distribution\n",
    "sentiment_counts = df_supervised['sentiment_label'].value_counts()\n",
    "sentiment_percentages = df_supervised['sentiment_label'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Overall Sentiment Distribution:\")\n",
    "print(\"=\" * 40)\n",
    "for label in ['positive', 'neutral', 'negative']:\n",
    "    count = sentiment_counts. get(label, 0)\n",
    "    pct = sentiment_percentages.get(label, 0)\n",
    "    print(f\"{label. capitalize():10s}:  {count:>7,} comments ({pct:.2f}%)\")\n",
    "print(f\"{'Total':10s}: {len(df_supervised):>7,} comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# 1. Bar chart of sentiment counts\n",
    "colors = {'positive': '#2ecc71', 'neutral': '#3498db', 'negative':  '#e74c3c'}\n",
    "order = ['positive', 'neutral', 'negative']\n",
    "\n",
    "ax1 = axes[0]\n",
    "bars = ax1.bar(order, [sentiment_counts. get(s, 0) for s in order], \n",
    "               color=[colors[s] for s in order], edgecolor='black', linewidth=1. 2)\n",
    "ax1.set_xlabel('Sentiment', fontsize=12)\n",
    "ax1.set_ylabel('Number of Comments', fontsize=12)\n",
    "ax1.set_title('Sentiment Distribution (Counts)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, label in zip(bars, order):\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{int(height):,}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 2. Pie chart\n",
    "ax2 = axes[1]\n",
    "sizes = [sentiment_counts.get(s, 0) for s in order]\n",
    "explode = (0.02, 0.02, 0.02)\n",
    "ax2.pie(sizes, labels=[s.capitalize() for s in order], autopct='%1.1f%%',\n",
    "        colors=[colors[s] for s in order], explode=explode,\n",
    "        startangle=90, textprops={'fontsize': 11})\n",
    "ax2.set_title('Sentiment Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Distribution of compound scores\n",
    "ax3 = axes[2]\n",
    "ax3.hist(df_supervised['sentiment_compound'], bins=50, color='steelblue', \n",
    "         edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(x=0.05, color='green', linestyle='--', label='Positive threshold (0.05)')\n",
    "ax3.axvline(x=-0.05, color='red', linestyle='--', label='Negative threshold (-0.05)')\n",
    "ax3.set_xlabel('Compound Score', fontsize=12)\n",
    "ax3.set_ylabel('Frequency', fontsize=12)\n",
    "ax3.set_title('Distribution of Compound Scores', fontsize=14, fontweight='bold')\n",
    "ax3.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_overall_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Statistics on compound scores\n",
    "print(\"\\nCompound Score Statistics:\")\n",
    "print(df_supervised['sentiment_compound'].describe())"
   ]
  },
  {
   "cell_type":  "markdown",
   "metadata": {},
   "source": [
    "## 5. Sentiment Distribution per Subreddit (Task 1c)\n",
    "\n",
    "Visualize sentiment distribution per subreddit using bar charts or heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sentiment distribution per subreddit\n",
    "subreddit_sentiment = df_supervised.groupby(['subreddit', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate percentages\n",
    "subreddit_sentiment_pct = subreddit_sentiment. div(subreddit_sentiment. sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Get top 20 subreddits by comment count\n",
    "top_subreddits = df_supervised['subreddit'].value_counts().head(20).index.tolist()\n",
    "\n",
    "print(f\"Total unique subreddits: {df_supervised['subreddit'].nunique()}\")\n",
    "print(f\"\\nTop 20 subreddits by comment count:\")\n",
    "print(df_supervised['subreddit'].value_counts().head(20))"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart:  Top 20 subreddits sentiment distribution\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Filter to top subreddits and reorder columns\n",
    "plot_data = subreddit_sentiment_pct. loc[top_subreddits][['positive', 'neutral', 'negative']]\n",
    "\n",
    "# Stacked bar chart\n",
    "plot_data.plot(kind='barh', stacked=True, ax=ax,\n",
    "               color=[colors['positive'], colors['neutral'], colors['negative']],\n",
    "               edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Percentage (%)', fontsize=12)\n",
    "ax.set_ylabel('Subreddit', fontsize=12)\n",
    "ax.set_title('Sentiment Distribution by Subreddit (Top 20)', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Sentiment', loc='lower right')\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_by_subreddit_bar. png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap:  Sentiment distribution across top subreddits\n",
    "fig, ax = plt. subplots(figsize=(10, 12))\n",
    "\n",
    "# Prepare data for heatmap\n",
    "heatmap_data = subreddit_sentiment_pct.loc[top_subreddits][['positive', 'neutral', 'negative']]\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.1f', cmap='RdYlGn', \n",
    "            center=50, ax=ax, linewidths=0.5,\n",
    "            cbar_kws={'label': 'Percentage (%)'})\n",
    "\n",
    "ax.set_xlabel('Sentiment', fontsize=12)\n",
    "ax.set_ylabel('Subreddit', fontsize=12)\n",
    "ax.set_title('Sentiment Distribution Heatmap (Top 20 Subreddits)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_by_subreddit_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average compound score per subreddit\n",
    "subreddit_compound = df_supervised.groupby('subreddit')['sentiment_compound']. agg(['mean', 'std', 'count'])\n",
    "subreddit_compound = subreddit_compound.sort_values('mean', ascending=False)\n",
    "\n",
    "# Filter subreddits with at least 100 comments for reliability\n",
    "subreddit_compound_filtered = subreddit_compound[subreddit_compound['count'] >= 100]\n",
    "\n",
    "print(\"Most Positive Subreddits (min 100 comments):\")\n",
    "print(subreddit_compound_filtered.head(10))\n",
    "\n",
    "print(\"\\nMost Negative Subreddits (min 100 comments):\")\n",
    "print(subreddit_compound_filtered.tail(10))"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 10 most positive and negative subreddits\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Most positive\n",
    "top_positive = subreddit_compound_filtered.head(10)\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.barh(top_positive.index, top_positive['mean'], color='#2ecc71', edgecolor='black')\n",
    "ax1.set_xlabel('Average Compound Score', fontsize=12)\n",
    "ax1.set_title('Top 10 Most Positive Subreddits', fontsize=14, fontweight='bold')\n",
    "ax1.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Most negative\n",
    "top_negative = subreddit_compound_filtered.tail(10)\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.barh(top_negative.index, top_negative['mean'], color='#e74c3c', edgecolor='black')\n",
    "ax2.set_xlabel('Average Compound Score', fontsize=12)\n",
    "ax2.set_title('Top 10 Most Negative Subreddits', fontsize=14, fontweight='bold')\n",
    "ax2.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_extreme_subreddits.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type":  "markdown",
   "metadata":  {},
   "source": [
    "## 6. Sentiment Correlation with Gender (Task 1d)\n",
    "\n",
    "Does sentiment correlate with gender? Do male or female users tend to post more positive or negative comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs":  [],
   "source": [
    "# Merge sentiment data with gender information\n",
    "# First, we need to map authors to their genders\n",
    "\n",
    "# Get unique authors from supervised data\n",
    "authors_supervised = df_supervised['author'].unique()\n",
    "print(f\"Unique authors in supervised data: {len(authors_supervised)}\")\n",
    "print(f\"Number of entries in target file: {len(df_target)}\")"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of target file\n",
    "print(\"Target file structure:\")\n",
    "print(df_target. head())\n",
    "print(f\"\\nTarget columns: {df_target.columns. tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create author-gender mapping\n",
    "# Assuming target file has 'author' and 'gender' columns\n",
    "# If structure is different, adjust accordingly\n",
    "\n",
    "# Option 1: If target has author column\n",
    "if 'author' in df_target.columns:\n",
    "    author_gender_map = df_target. set_index('author')['gender'].to_dict()\n",
    "else:\n",
    "    # Option 2: If target is aligned with unique authors\n",
    "    # Get unique authors in order they appear\n",
    "    unique_authors = df_supervised. groupby('author').first().reset_index()['author']\n",
    "    author_gender_map = dict(zip(unique_authors, df_target['gender']))\n",
    "\n",
    "# Map gender to comments\n",
    "df_supervised['gender'] = df_supervised['author'].map(author_gender_map)\n",
    "\n",
    "# Check mapping success\n",
    "print(f\"Comments with gender info: {df_supervised['gender'].notna().sum()}\")\n",
    "print(f\"Comments without gender info: {df_supervised['gender'].isna().sum()}\")\n",
    "\n",
    "# Gender distribution (0=male, 1=female)\n",
    "print(f\"\\nGender distribution in comments:\")\n",
    "print(df_supervised['gender']. value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map numeric gender to labels\n",
    "df_supervised['gender_label'] = df_supervised['gender'].map({0: 'Male', 1: 'Female'})\n",
    "\n",
    "# Calculate sentiment distribution by gender\n",
    "gender_sentiment = df_supervised.groupby(['gender_label', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "gender_sentiment_pct = gender_sentiment.div(gender_sentiment.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(\"Sentiment Distribution by Gender (Counts):\")\n",
    "print(gender_sentiment)\n",
    "\n",
    "print(\"\\nSentiment Distribution by Gender (Percentages):\")\n",
    "print(gender_sentiment_pct. round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison of compound scores by gender\n",
    "male_compound = df_supervised[df_supervised['gender_label'] == 'Male']['sentiment_compound']\n",
    "female_compound = df_supervised[df_supervised['gender_label'] == 'Female']['sentiment_compound']\n",
    "\n",
    "print(\"Compound Score Statistics by Gender:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nMale users: \")\n",
    "print(f\"  Mean: {male_compound.mean():.4f}\")\n",
    "print(f\"  Std:   {male_compound.std():.4f}\")\n",
    "print(f\"  Median: {male_compound.median():.4f}\")\n",
    "print(f\"  Count: {len(male_compound):,}\")\n",
    "\n",
    "print(f\"\\nFemale users: \")\n",
    "print(f\"  Mean: {female_compound.mean():.4f}\")\n",
    "print(f\"  Std:   {female_compound.std():.4f}\")\n",
    "print(f\"  Median: {female_compound. median():.4f}\")\n",
    "print(f\"  Count: {len(female_compound):,}\")\n",
    "\n",
    "# Statistical test (Mann-Whitney U test - non-parametric)\n",
    "statistic, p_value = stats.mannwhitneyu(male_compound, female_compound, alternative='two-sided')\n",
    "print(f\"\\nMann-Whitney U Test: \")\n",
    "print(f\"  Statistic:  {statistic: ,.0f}\")\n",
    "print(f\"  P-value: {p_value:.6f}\")\n",
    "print(f\"  Significant difference (α=0.05): {'Yes' if p_value < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations for gender-sentiment correlation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Bar chart: Sentiment distribution by gender\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "sentiments = ['positive', 'neutral', 'negative']\n",
    "\n",
    "male_pct = [gender_sentiment_pct.loc['Male', s] for s in sentiments]\n",
    "female_pct = [gender_sentiment_pct.loc['Female', s] for s in sentiments]\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, male_pct, width, label='Male', color='#3498db', edgecolor='black')\n",
    "bars2 = ax1.bar(x + width/2, female_pct, width, label='Female', color='#e91e63', edgecolor='black')\n",
    "\n",
    "ax1.set_xlabel('Sentiment', fontsize=12)\n",
    "ax1.set_ylabel('Percentage (%)', fontsize=12)\n",
    "ax1.set_title('Sentiment Distribution by Gender', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([s.capitalize() for s in sentiments])\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, max(max(male_pct), max(female_pct)) * 1.1)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    ax1.annotate(f'{bar.get_height():.1f}%', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "for bar in bars2:\n",
    "    ax1.annotate(f'{bar.get_height():.1f}%', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Box plot: Compound score distribution by gender\n",
    "ax2 = axes[0, 1]\n",
    "df_supervised. boxplot(column='sentiment_compound', by='gender_label', ax=ax2,\n",
    "                      patch_artist=True,\n",
    "                      boxprops=dict(facecolor='lightblue'),\n",
    "                      medianprops=dict(color='red', linewidth=2))\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Compound Score', fontsize=12)\n",
    "ax2.set_title('Compound Score Distribution by Gender', fontsize=14, fontweight='bold')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "# 3. Violin plot: Detailed distribution\n",
    "ax3 = axes[1, 0]\n",
    "sns.violinplot(data=df_supervised, x='gender_label', y='sentiment_compound', \n",
    "               palette=['#3498db', '#e91e63'], ax=ax3)\n",
    "ax3.set_xlabel('Gender', fontsize=12)\n",
    "ax3.set_ylabel('Compound Score', fontsize=12)\n",
    "ax3.set_title('Sentiment Distribution (Violin Plot)', fontsize=14, fontweight='bold')\n",
    "ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 4. KDE plot: Density comparison\n",
    "ax4 = axes[1, 1]\n",
    "sns.kdeplot(data=male_compound, ax=ax4, label='Male', color='#3498db', fill=True, alpha=0.3)\n",
    "sns.kdeplot(data=female_compound, ax=ax4, label='Female', color='#e91e63', fill=True, alpha=0.3)\n",
    "ax4.axvline(x=male_compound.mean(), color='#3498db', linestyle='--', label=f'Male Mean ({male_compound.mean():.3f})')\n",
    "ax4.axvline(x=female_compound.mean(), color='#e91e63', linestyle='--', label=f'Female Mean ({female_compound. mean():.3f})')\n",
    "ax4.set_xlabel('Compound Score', fontsize=12)\n",
    "ax4.set_ylabel('Density', fontsize=12)\n",
    "ax4.set_title('Compound Score Density by Gender', fontsize=14, fontweight='bold')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_by_gender.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by user:  Average sentiment per user\n",
    "user_sentiment = df_supervised.groupby(['author', 'gender_label']).agg({\n",
    "    'sentiment_compound':  'mean',\n",
    "    'sentiment_pos': 'mean',\n",
    "    'sentiment_neg': 'mean',\n",
    "    'body':  'count'\n",
    "}).rename(columns={'body': 'num_comments'}).reset_index()\n",
    "\n",
    "print(f\"\\nUser-level sentiment statistics:\")\n",
    "print(user_sentiment. groupby('gender_label')['sentiment_compound'].describe())"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-level comparison\n",
    "male_users = user_sentiment[user_sentiment['gender_label'] == 'Male']['sentiment_compound']\n",
    "female_users = user_sentiment[user_sentiment['gender_label'] == 'Female']['sentiment_compound']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.kdeplot(data=male_users, ax=ax, label=f'Male (n={len(male_users)})', \n",
    "            color='#3498db', fill=True, alpha=0.3)\n",
    "sns.kdeplot(data=female_users, ax=ax, label=f'Female (n={len(female_users)})', \n",
    "            color='#e91e63', fill=True, alpha=0.3)\n",
    "\n",
    "ax. axvline(x=male_users.mean(), color='#3498db', linestyle='--', linewidth=2)\n",
    "ax.axvline(x=female_users.mean(), color='#e91e63', linestyle='--', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Average Compound Score per User', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('User-Level Average Sentiment by Gender', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "# Statistical test at user level\n",
    "stat_user, p_user = stats.mannwhitneyu(male_users, female_users, alternative='two-sided')\n",
    "ax.text(0.02, 0.98, f'Mann-Whitney U p-value: {p_user:. 4f}', \n",
    "        transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_by_gender_user_level.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nUser-level Mann-Whitney U Test:\")\n",
    "print(f\"  P-value: {p_user:. 6f}\")\n",
    "print(f\"  Significant difference (α=0.05): {'Yes' if p_user < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SECTION 4 - SENTIMENT ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. PREPROCESSING: \")\n",
    "print(\"   - Used minimal preprocessing for sentiment analysis\")\n",
    "print(\"   - Preserved negation words (not, never, no) - crucial for sentiment! \")\n",
    "print(\"   - Kept punctuation (!  ?) and case sensitivity\")\n",
    "print(\"   - Only removed URLs and Reddit-specific references\")\n",
    "\n",
    "print(\"\\n2. OVERALL SENTIMENT DISTRIBUTION:\")\n",
    "for label in ['positive', 'neutral', 'negative']:\n",
    "    pct = sentiment_percentages. get(label, 0)\n",
    "    print(f\"   - {label. capitalize()}: {pct:.1f}%\")\n",
    "\n",
    "print(\"\\n3. SUBREDDIT ANALYSIS:\")\n",
    "print(f\"   - Analyzed {df_supervised['subreddit'].nunique()} unique subreddits\")\n",
    "print(f\"   - Most positive subreddit: {subreddit_compound_filtered.index[0]}\")\n",
    "print(f\"   - Most negative subreddit: {subreddit_compound_filtered.index[-1]}\")\n",
    "\n",
    "print(\"\\n4. GENDER CORRELATION:\")\n",
    "print(f\"   - Male avg compound score: {male_compound.mean():.4f}\")\n",
    "print(f\"   - Female avg compound score: {female_compound.mean():.4f}\")\n",
    "print(f\"   - Difference: {abs(male_compound. mean() - female_compound.mean()):.4f}\")\n",
    "print(f\"   - Statistical significance (p<0.05): {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "if female_compound.mean() > male_compound.mean():\n",
    "    print(\"   - Finding:  Female users tend to post slightly more positive comments\")\n",
    "else:\n",
    "    print(\"   - Finding: Male users tend to post slightly more positive comments\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for Section 2 integration\n",
    "sentiment_features = df_supervised[['author', 'subreddit', 'sentiment_compound', \n",
    "                                     'sentiment_pos', 'sentiment_neg', 'sentiment_neu',\n",
    "                                     'sentiment_label', 'gender']]\n",
    "sentiment_features.to_csv('sentiment_features.csv', index=False)\n",
    "\n",
    "# Save user-level aggregated sentiment\n",
    "user_sentiment. to_csv('user_sentiment_aggregated.csv', index=False)\n",
    "\n",
    "print(\"Saved files:\")\n",
    "print(\"  - sentiment_features.csv (comment-level)\")\n",
    "print(\"  - user_sentiment_aggregated.csv (user-level)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor":  4
}