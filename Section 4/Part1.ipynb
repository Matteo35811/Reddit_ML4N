{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SECTION 4 - SENTIMENT ANALYSIS\n",
    "\n",
    "### PART 1 - CLASSICAL ANALYSIS\n",
    "Try using VADER from NLTK or HuggingFace transformers. The aim is to classify each comment in the supervised dataset as positive,\n",
    "negative, or neutral.\n",
    "\n",
    "a. Note that for sentiment analysis removing some stopwords (e.g., â€œnotâ€, â€œneverâ€, â€œnoâ€) may\n",
    "be harmful. Slightly adjust your preprocessing pipeline if you deem it useful.\n",
    "\n",
    "b. What is the overall sentiment distribution across all comments?\n",
    "\n",
    "c. Visualize sentiment distribution per subreddit using bar charts or heatmaps.\n",
    "\n",
    "d. Does sentiment correlate with gender?"
   ],
   "id": "a4773dd9892c2ab7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Setup and Data",
   "id": "9ccf2fac926728a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy matplotlib seaborn nltk scipy"
   ],
   "id": "b93d61b46723d96b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib. pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment. vader import SentimentIntensityAnalyzer\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')"
   ],
   "id": "c8c9fc7cd286695d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the supervised dataset\n",
    "# For sentiment analysis, we need the original text with stopwords intact\n",
    "\n",
    "df_supervised = pd.read_csv('../data/data_supervised.csv')\n",
    "df_target = pd.read_csv('../data/target_supervised.csv')\n",
    "\n",
    "print(f\"Supervised dataset shape: {df_supervised. shape}\")\n",
    "print(f\"Target dataset shape: {df_target.shape}\")\n",
    "print(f\"\\nColumns in supervised data: {df_supervised.columns.tolist()}\")\n",
    "print(f\"Columns in target data: {df_target.columns.tolist()}\")"
   ],
   "id": "7f174627e6466592",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preview the data\n",
    "print(\"Sample comments:\")\n",
    "df_supervised.head()"
   ],
   "id": "4f47ee846f4ab90a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. PREPROCESSING\n",
    "Remember that is important to NOT remove negation words like \"not\", \"never\", \"no\" as they change the sentiment of a sentence.\n",
    "\n",
    "Thus we apply minimal preprocessing that preserves sentiment-bearing words.\n",
    "\n",
    "### NOTE\n",
    "IT IS VERY IMPORTANT TO REMOVE NON-ENGLISH LANGUAGES SINCE VADER CAN'T REALLY WORK. VADER only works on English, meaningless results on other languages. Must remove non-English for accurate sentiment scores.\n"
   ],
   "id": "415f4e68d65ba4ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# LANGUAGE FILTERING - Remove non-English comments before vectorization\n",
    "# =============================================================================\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Deterministic results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def detect_lang_safe(text:  str) -> str:\n",
    "    \"\"\"Safely detect language, handling edge cases\"\"\"\n",
    "    try:\n",
    "        if not isinstance(text, str) or len(text. strip()) < 3:\n",
    "            return \"short_text\"  # Keep short text (assumed English)\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"short_text\"\n",
    "\n",
    "# Check if language column already exists, otherwise detect\n",
    "if 'lang' not in df_supervised.columns:\n",
    "    print(\"Detecting languages in supervised dataset...\")\n",
    "    tqdm.pandas(desc=\"Language detection\")\n",
    "    df_supervised['lang'] = df_supervised['body'].fillna('').astype(str).str.strip().progress_apply(detect_lang_safe)\n",
    "\n",
    "    # Show distribution\n",
    "    print(\"\\nLanguage distribution:\")\n",
    "    print(df_supervised['lang'].value_counts().head(15))\n",
    "\n",
    "# Filter:  keep only English + short_text (assumed English)\n",
    "print(f\"\\nBefore filtering: {len(df_supervised)} comments\")\n",
    "df_supervised_en = df_supervised[df_supervised['lang']. isin(['en', 'short_text'])].copy()\n",
    "\n",
    "# Stats\n",
    "n_removed = len(df_supervised) - len(df_supervised_en)\n",
    "pct_kept = len(df_supervised_en) / len(df_supervised) * 100\n",
    "print(f\"After filtering (English only): {len(df_supervised_en)} comments\")\n",
    "print(f\"Removed: {n_removed} non-English comments ({100-pct_kept:.1f}%)\")\n",
    "\n",
    "# Overwrite for subsequent processing\n",
    "df_supervised = df_supervised_en.drop(columns=['lang']).reset_index(drop=True)\n",
    "print(f\"\\n'df_supervised' now contains {len(df_supervised)} English comments\")"
   ],
   "id": "21ecef53c0dd0864",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import html\n",
    "import re\n",
    "\n",
    "def preprocess_for_sentiment(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    # Decode HTML entities (e.g., &amp; -> &)\n",
    "    text = html.unescape(text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    # Remove subreddit and user references (r/...  and u/... )\n",
    "    text = re.sub(r'r/\\w+|u/\\w+', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df_supervised['body_sentiment'] = df_supervised['body'].apply(preprocess_for_sentiment)\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(f\"Empty bodies after preprocessing: {(df_supervised['body_sentiment'] == '').sum()}\")"
   ],
   "id": "8050f54a5b65d143",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Show comparison between original and preprocessed text\n",
    "comparison_df = df_supervised[['body', 'body_sentiment']].head(5)\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    print(f\"--- Comment {idx} ---\")\n",
    "    print(f\"Original: {row['body'][:200]}...\" if len(str(row['body'])) > 200 else f\"Original: {row['body']}\")\n",
    "    print(f\"Preprocessed: {row['body_sentiment'][:200]}...\" if len(row['body_sentiment']) > 200 else f\"Preprocessed:  {row['body_sentiment']}\")\n",
    "    print()"
   ],
   "id": "9db92d185e064697",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Sentiment Analysis with VADER",
   "id": "fbd3004b7e86ad8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**VADER (Valence Aware Dictionary and sEntiment Reasoner)** is a lexicon and rule-based sentiment analysis tool specifically attuned to sentiments expressed in social media.\n",
    "\n",
    "VADER returns 4 scores:\n",
    "- `neg`: Negative sentiment proportion\n",
    "- `neu`: Neutral sentiment proportion\n",
    "- `pos`: Positive sentiment proportion\n",
    "- `compound`: Normalized, weighted composite score (-1 to +1)\n",
    "\n",
    "Classification thresholds (standard):\n",
    "- Positive: compound >= 0.05\n",
    "- Negative: compound <= -0.05\n",
    "- Neutral: -0.05 < compound < 0.05"
   ],
   "id": "935d8741d6c3e7ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Initialize VADER\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_scores(text):\n",
    "    if not text or text == \"\":\n",
    "        return {'neg': 0, 'neu': 1, 'pos': 0, 'compound': 0}\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "def classify_sentiment(compound_score):\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "print(\"Analyzing sentiment for all comments... \")\n",
    "sentiment_scores = df_supervised['body_sentiment'].progress_apply(get_sentiment_scores)\n",
    "\n",
    "# Extract individual scores\n",
    "df_supervised['sentiment_neg'] = sentiment_scores. apply(lambda x: x['neg'])\n",
    "df_supervised['sentiment_neu'] = sentiment_scores.apply(lambda x: x['neu'])\n",
    "df_supervised['sentiment_pos'] = sentiment_scores. apply(lambda x: x['pos'])\n",
    "df_supervised['sentiment_compound'] = sentiment_scores.apply(lambda x: x['compound'])\n",
    "\n",
    "# Classify sentiment\n",
    "df_supervised['sentiment_label'] = df_supervised['sentiment_compound'].apply(classify_sentiment)\n",
    "\n",
    "print(\"\\nSentiment analysis complete!\")"
   ],
   "id": "7246912a24317489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preview results\n",
    "df_supervised[['body_sentiment', 'sentiment_compound', 'sentiment_label']]. head(10)"
   ],
   "id": "845c868824877c68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Sentiment Distribution (Task 1b)",
   "id": "b6d279155851d885"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate sentiment distribution\n",
    "sentiment_counts = df_supervised['sentiment_label'].value_counts()\n",
    "sentiment_percentages = df_supervised['sentiment_label'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Overall Sentiment Distribution:\")\n",
    "print(\"=\" * 40)\n",
    "for label in ['positive', 'neutral', 'negative']:\n",
    "    count = sentiment_counts. get(label, 0)\n",
    "    pct = sentiment_percentages.get(label, 0)\n",
    "    print(f\"{label. capitalize():10s}:  {count:>7,} comments ({pct:.2f}%)\")\n",
    "print(f\"{'Total':10s}: {len(df_supervised):>7,} comments\")"
   ],
   "id": "4fc80997c121373d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compound score statistics\n",
    "print(\"\\nCompound Score Statistics:\")\n",
    "print(df_supervised['sentiment_compound'].describe())"
   ],
   "id": "dda3de15c88fefc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize sentiment distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# 1. Bar chart of sentiment counts\n",
    "colors = {'positive': '#008C3A', 'neutral': '#0000CC', 'negative':  '#7C090C'}\n",
    "order = ['positive', 'neutral', 'negative']\n",
    "\n",
    "ax1 = axes[0]\n",
    "bars = ax1.bar(order, [sentiment_counts. get(s, 0) for s in order],\n",
    "               color=[colors[s] for s in order], edgecolor='black', linewidth=1.2)\n",
    "ax1.set_xlabel('Sentiment', fontsize=12)\n",
    "ax1.set_ylabel('Number of Comments', fontsize=12)\n",
    "ax1.set_title('Sentiment Distribution (Counts)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, label in zip(bars, order):\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{int(height):,}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 2. Pie chart\n",
    "ax2 = axes[1]\n",
    "sizes = [sentiment_counts.get(s, 0) for s in order]\n",
    "explode = (0.02, 0.02, 0.02)\n",
    "ax2.pie(sizes, labels=[s.capitalize() for s in order], autopct='%1.1f%%',\n",
    "        colors=[colors[s] for s in order], explode=explode,\n",
    "        startangle=90, textprops={'fontsize': 11})\n",
    "ax2.set_title('Sentiment Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Distribution of compound scores\n",
    "ax3 = axes[2]\n",
    "ax3.hist(df_supervised['sentiment_compound'], bins=50, color='steelblue',\n",
    "         edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(x=0.05, color='green', linestyle='--', label='Positive threshold (0.05)')\n",
    "ax3.axvline(x=-0.05, color='red', linestyle='--', label='Negative threshold (-0.05)')\n",
    "ax3.set_xlabel('Compound Score', fontsize=12)\n",
    "ax3.set_ylabel('Frequency', fontsize=12)\n",
    "ax3.set_title('Distribution of Compound Scores', fontsize=14, fontweight='bold')\n",
    "ax3.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_overall_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Statistics on compound scores\n",
    "print(\"\\nCompound Score Statistics:\")\n",
    "print(df_supervised['sentiment_compound'].describe())"
   ],
   "id": "57e26256de7fc16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Sentiment Distribution per Subreddit (Task 1c)\n",
    "\n",
    "**Question:** Visualize sentiment distribution per subreddit using bar charts or heatmaps."
   ],
   "id": "42dfe1130eb0e0a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculate sentiment distribution per subreddit\n",
    "subreddit_sentiment = df_supervised.groupby(['subreddit', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate percentages\n",
    "subreddit_sentiment_pct = subreddit_sentiment.div(subreddit_sentiment.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Reorder columns if they exist\n",
    "cols_order = ['positive', 'neutral', 'negative']\n",
    "cols_present = [c for c in cols_order if c in subreddit_sentiment_pct.columns]\n",
    "subreddit_sentiment_pct = subreddit_sentiment_pct[cols_present]\n",
    "\n",
    "# Get top 20 subreddits by comment count\n",
    "top_subreddits = df_supervised['subreddit'].value_counts().head(20).index.tolist()\n",
    "\n",
    "print(f\"Total unique subreddits: {df_supervised['subreddit'].nunique()}\")\n",
    "print(f\"\\nTop 20 subreddits by comment count:\")\n",
    "print(df_supervised['subreddit'].value_counts().head(20))\n"
   ],
   "id": "3da9302e1333a01d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Average compound score per subreddit\n",
    "subreddit_compound = df_supervised.groupby('subreddit')['sentiment_compound'].agg(['mean', 'std', 'count'])\n",
    "subreddit_compound = subreddit_compound.sort_values('mean', ascending=False)\n",
    "\n",
    "# Filter subreddits with at least 100 comments for reliability\n",
    "subreddit_compound_filtered = subreddit_compound[subreddit_compound['count'] >= 100]\n",
    "\n",
    "print(\"\\nMost POSITIVE Subreddits (min 100 comments):\")\n",
    "print(subreddit_compound_filtered.head(10))\n",
    "\n",
    "print(\"\\nMost NEGATIVE Subreddits (min 100 comments):\")\n",
    "print(subreddit_compound_filtered.tail(10))\n"
   ],
   "id": "f18ef10b42a66539",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Stacked horizontal bar chart for top 20 subreddits\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Filter to top subreddits\n",
    "plot_data = subreddit_sentiment_pct.loc[top_subreddits][cols_present]\n",
    "\n",
    "# Create stacked bar chart\n",
    "plot_data.plot(kind='barh', stacked=True, ax=ax,\n",
    "               color=[colors. get(c, 'gray') for c in cols_present],\n",
    "               edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Percentage (%)', fontsize=12)\n",
    "ax.set_ylabel('Subreddit', fontsize=12)\n",
    "ax.set_title('Sentiment Distribution by Subreddit (Top 20 by Comment Count)', fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Sentiment', loc='lower right', fontsize=10)\n",
    "ax.set_xlim(0, 100)\n",
    "ax.xaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.2_sentiment_by_subreddit_bar.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "1b8266b380348dfe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Heatmap of sentiment distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "# Prepare heatmap data\n",
    "heatmap_data = subreddit_sentiment_pct.loc[top_subreddits][cols_present]\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(heatmap_data,\n",
    "            annot=True,\n",
    "            fmt='.1f',\n",
    "            cmap='RdYlGn',\n",
    "            center=50,\n",
    "            ax=ax,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={'label': 'Percentage (%)'})\n",
    "\n",
    "ax.set_xlabel('Sentiment', fontsize=12)\n",
    "ax.set_ylabel('Subreddit', fontsize=12)\n",
    "ax.set_title('Sentiment Distribution Heatmap (Top 20 Subreddits)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.3_sentiment_by_subreddit_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "1c4b8b30a0386f9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5 Most Positive and Negative Subreddits\n",
   "id": "e5051e0ded328123"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Bar chart comparing most positive vs most negative subreddits\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top 10 most positive subreddits\n",
    "top_positive = subreddit_compound_filtered.head(10)\n",
    "ax1 = axes[0]\n",
    "bars1 = ax1.barh(top_positive. index, top_positive['mean'], color='#2ecc71', edgecolor='black')\n",
    "ax1.set_xlabel('Average Compound Score', fontsize=12)\n",
    "ax1.set_ylabel('Subreddit', fontsize=12)\n",
    "ax1.set_title('Top 10 Most POSITIVE Subreddits', fontsize=14, fontweight='bold')\n",
    "ax1.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    width = bar.get_width()\n",
    "    ax1.annotate(f'{width:.3f}',\n",
    "                 xy=(width, bar.get_y() + bar.get_height()/2),\n",
    "                 ha='left', va='center', fontsize=9, xytext=(5, 0),\n",
    "                 textcoords='offset points')\n",
    "\n",
    "# Top 10 most negative subreddits\n",
    "top_negative = subreddit_compound_filtered.tail(10)\n",
    "ax2 = axes[1]\n",
    "bars2 = ax2.barh(top_negative. index, top_negative['mean'], color='#e74c3c', edgecolor='black')\n",
    "ax2.set_xlabel('Average Compound Score', fontsize=12)\n",
    "ax2.set_ylabel('Subreddit', fontsize=12)\n",
    "ax2.set_title('Top 10 Most NEGATIVE Subreddits', fontsize=14, fontweight='bold')\n",
    "ax2.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars2:\n",
    "    width = bar.get_width()\n",
    "    ax2.annotate(f'{width:.3f}',\n",
    "                 xy=(width, bar.get_y() + bar.get_height()/2),\n",
    "                 ha='right' if width < 0 else 'left', va='center', fontsize=9,\n",
    "                 xytext=(-5 if width < 0 else 5, 0),\n",
    "                 textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.4_sentiment_extreme_subreddits.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "9bd842f5ea06dc2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Grouped bar chart showing actual counts\n",
    "fig, ax = plt. subplots(figsize=(14, 8))\n",
    "\n",
    "# Get top 15 subreddits for cleaner visualization\n",
    "top_15_subs = df_supervised['subreddit'].value_counts().head(15).index.tolist()\n",
    "plot_counts = subreddit_sentiment. loc[top_15_subs][cols_present]\n",
    "\n",
    "# Set up bar positions\n",
    "x = np.arange(len(top_15_subs))\n",
    "width = 0.25\n",
    "\n",
    "# Create bars\n",
    "bars1 = ax.bar(x - width, plot_counts['positive'], width, label='Positive', color='#2ecc71', edgecolor='black')\n",
    "bars2 = ax.bar(x, plot_counts['neutral'], width, label='Neutral', color='#3498db', edgecolor='black')\n",
    "bars3 = ax.bar(x + width, plot_counts['negative'], width, label='Negative', color='#e74c3c', edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Subreddit', fontsize=12)\n",
    "ax.set_ylabel('Number of Comments', fontsize=12)\n",
    "ax.set_title('Sentiment Counts by Subreddit (Top 15)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(top_15_subs, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.5_sentiment_counts_by_subreddit.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "cbf33cd71e2baf01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Sentiment Correlation with Gender (Task 1d)\n",
    "\n",
    "**Question:** Does sentiment correlate with gender?  Do male or female users tend to post\n",
    "more positive or negative comments?\n"
   ],
   "id": "6914171cdfc6140d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check the structure of the target file\n",
    "print(\"Target file structure:\")\n",
    "print(df_target.head())\n",
    "print(f\"\\nTarget columns: {df_target.columns.tolist()}\")\n",
    "print(f\"Target shape: {df_target.shape}\")\n",
    "# Create author-gender mapping\n",
    "if 'author' in df_target.columns:\n",
    "    # If target has author column\n",
    "    author_gender_map = df_target.set_index('author')['gender'].to_dict()\n",
    "    print(\"Using 'author' column from target file for mapping\")\n",
    "else:\n",
    "    # If target is aligned with unique authors\n",
    "    unique_authors = df_supervised.drop_duplicates('author')['author'].tolist()\n",
    "\n",
    "    if len(unique_authors) == len(df_target):\n",
    "        author_gender_map = dict(zip(unique_authors, df_target['gender']))\n",
    "        print(\"Mapping based on author order alignment\")\n",
    "    else:\n",
    "        # Try sorting alphabetically\n",
    "        unique_authors_sorted = sorted(df_supervised['author'].unique())\n",
    "        author_gender_map = dict(zip(unique_authors_sorted, df_target['gender']))\n",
    "        print(\"Mapping based on alphabetically sorted authors\")\n",
    "\n",
    "print(f\"\\nTotal authors mapped: {len(author_gender_map)}\")\n",
    "# Apply gender mapping to dataframe\n",
    "df_supervised['gender'] = df_supervised['author'].map(author_gender_map)\n",
    "\n",
    "# Create readable labels (0=Male, 1=Female as per project description)\n",
    "df_supervised['gender_label'] = df_supervised['gender'].map({0: 'Male', 1: 'Female'})\n",
    "\n",
    "# Check mapping success\n",
    "print(\"Gender Mapping Results:\")\n",
    "print(f\"Comments with gender info: {df_supervised['gender'].notna().sum():,}\")\n",
    "print(f\"Comments without gender info: {df_supervised['gender'].isna().sum():,}\")\n",
    "\n",
    "print(f\"\\nGender distribution in comments:\")\n",
    "print(df_supervised['gender_label'].value_counts())\n",
    "# Calculate sentiment distribution by gender\n",
    "gender_sentiment = df_supervised.groupby(['gender_label', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "gender_sentiment_pct = gender_sentiment.div(gender_sentiment.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(\"\\nSentiment Distribution by Gender (Counts):\")\n",
    "print(gender_sentiment)\n",
    "\n",
    "print(\"\\nSentiment Distribution by Gender (Percentages):\")\n",
    "print(gender_sentiment_pct. round(2))\n"
   ],
   "id": "68119c6cbe610a04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7 Statistical Analysis - Gender vs Sentiment\n",
   "id": "dcbbbb4107e60bc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract compound scores by gender\n",
    "male_compound = df_supervised[df_supervised['gender_label'] == 'Male']['sentiment_compound']. dropna()\n",
    "female_compound = df_supervised[df_supervised['gender_label'] == 'Female']['sentiment_compound'].dropna()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STATISTICAL ANALYSIS:  Sentiment by Gender\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n--- MALE Users ---\")\n",
    "print(f\"  Number of comments: {len(male_compound):,}\")\n",
    "print(f\"  Mean compound score: {male_compound. mean():.4f}\")\n",
    "print(f\"  Std deviation: {male_compound.std():.4f}\")\n",
    "print(f\"  Median:  {male_compound.median():.4f}\")\n",
    "print(f\"  Min: {male_compound. min():.4f}\")\n",
    "print(f\"  Max: {male_compound.max():.4f}\")\n",
    "\n",
    "print(f\"\\n--- FEMALE Users ---\")\n",
    "print(f\"  Number of comments: {len(female_compound):,}\")\n",
    "print(f\"  Mean compound score: {female_compound.mean():.4f}\")\n",
    "print(f\"  Std deviation: {female_compound.std():.4f}\")\n",
    "print(f\"  Median: {female_compound. median():.4f}\")\n",
    "print(f\"  Min: {female_compound.min():.4f}\")\n",
    "print(f\"  Max: {female_compound.max():.4f}\")\n",
    "\n",
    "print(f\"\\n--- DIFFERENCE ---\")\n",
    "mean_diff = female_compound.mean() - male_compound.mean()\n",
    "print(f\"  Difference in means (Female - Male): {mean_diff:.4f}\")\n",
    "if mean_diff > 0:\n",
    "    print(f\"  â†’ Female users are slightly MORE POSITIVE on average\")\n",
    "else:\n",
    "    print(f\"  â†’ Male users are slightly MORE POSITIVE on average\")\n"
   ],
   "id": "3334d45e5b007f47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Statistical Tests\n",
    "\n",
    "# 1. Mann-Whitney U Test (non-parametric, good for non-normal distributions)\n",
    "statistic_mw, p_value_mw = stats.mannwhitneyu(male_compound, female_compound, alternative='two-sided')\n",
    "\n",
    "# 2. Independent t-test (parametric)\n",
    "statistic_t, p_value_t = stats.ttest_ind(male_compound, female_compound)\n",
    "\n",
    "# 3. Effect size (Cohen's d)\n",
    "pooled_std = np.sqrt(((len(male_compound)-1)*male_compound.std()**2 +\n",
    "                       (len(female_compound)-1)*female_compound.std()**2) /\n",
    "                      (len(male_compound) + len(female_compound) - 2))\n",
    "cohens_d = (female_compound.mean() - male_compound.mean()) / pooled_std\n",
    "\n",
    "print(\"\\n--- STATISTICAL TESTS ---\")\n",
    "print(f\"\\n1. Mann-Whitney U Test (non-parametric):\")\n",
    "print(f\"   Statistic: {statistic_mw: ,.0f}\")\n",
    "print(f\"   P-value: {p_value_mw:.6f}\")\n",
    "print(f\"   Significant at Î±=0.05: {'YES' if p_value_mw < 0.05 else 'NO'}\")\n",
    "print(f\"   Significant at Î±=0.01: {'YES' if p_value_mw < 0.01 else 'NO'}\")\n",
    "\n",
    "print(f\"\\n2. Independent t-test (parametric):\")\n",
    "print(f\"   Statistic: {statistic_t:.4f}\")\n",
    "print(f\"   P-value: {p_value_t:.6f}\")\n",
    "print(f\"   Significant at Î±=0.05: {'YES' if p_value_t < 0.05 else 'NO'}\")\n",
    "\n",
    "print(f\"\\n3. Effect Size (Cohen's d): {cohens_d:.4f}\")\n",
    "if abs(cohens_d) < 0.2:\n",
    "    effect_interpretation = \"negligible\"\n",
    "elif abs(cohens_d) < 0.5:\n",
    "    effect_interpretation = \"small\"\n",
    "elif abs(cohens_d) < 0.8:\n",
    "    effect_interpretation = \"medium\"\n",
    "else:\n",
    "    effect_interpretation = \"large\"\n",
    "print(f\"   Interpretation: {effect_interpretation} effect\")\n"
   ],
   "id": "8e925844b2d1c1a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Grouped Bar Chart - Sentiment percentages by gender\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "sentiments = ['positive', 'neutral', 'negative']\n",
    "\n",
    "male_pct = [gender_sentiment_pct.loc['Male', s] if s in gender_sentiment_pct.columns else 0 for s in sentiments]\n",
    "female_pct = [gender_sentiment_pct. loc['Female', s] if s in gender_sentiment_pct. columns else 0 for s in sentiments]\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, male_pct, width, label='Male', color='#3498db', edgecolor='black')\n",
    "bars2 = ax1.bar(x + width/2, female_pct, width, label='Female', color='#e91e63', edgecolor='black')\n",
    "\n",
    "ax1.set_xlabel('Sentiment', fontsize=12)\n",
    "ax1.set_ylabel('Percentage (%)', fontsize=12)\n",
    "ax1.set_title('Sentiment Distribution by Gender', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([s.capitalize() for s in sentiments])\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, max(max(male_pct), max(female_pct)) * 1.15)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.1f}%', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                 ha='center', va='bottom', fontsize=9)\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height:.1f}%', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                 ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Box Plot - Compound score distribution\n",
    "ax2 = axes[0, 1]\n",
    "box_data = [male_compound, female_compound]\n",
    "bp = ax2.boxplot(box_data, labels=['Male', 'Female'], patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "bp['boxes'][0].set_facecolor('#3498db')\n",
    "bp['boxes'][1].set_facecolor('#e91e63')\n",
    "for median in bp['medians']:\n",
    "    median.set_color('black')\n",
    "    median.set_linewidth(2)\n",
    "\n",
    "ax2.set_xlabel('Gender', fontsize=12)\n",
    "ax2.set_ylabel('Compound Score', fontsize=12)\n",
    "ax2.set_title('Compound Score Distribution by Gender', fontsize=14, fontweight='bold')\n",
    "ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax2.yaxis.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# 3. Violin Plot - Detailed distribution shape\n",
    "ax3 = axes[1, 0]\n",
    "parts = ax3.violinplot([male_compound, female_compound], positions=[1, 2], showmeans=True, showmedians=True)\n",
    "\n",
    "# Color violins\n",
    "colors_violin = ['#3498db', '#e91e63']\n",
    "for i, pc in enumerate(parts['bodies']):\n",
    "    pc.set_facecolor(colors_violin[i])\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "ax3.set_xticks([1, 2])\n",
    "ax3.set_xticklabels(['Male', 'Female'])\n",
    "ax3.set_xlabel('Gender', fontsize=12)\n",
    "ax3.set_ylabel('Compound Score', fontsize=12)\n",
    "ax3.set_title('Sentiment Distribution (Violin Plot)', fontsize=14, fontweight='bold')\n",
    "ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 4. KDE Plot - Density comparison\n",
    "ax4 = axes[1, 1]\n",
    "sns.kdeplot(data=male_compound, ax=ax4, label=f'Male (Î¼={male_compound.mean():.3f})',\n",
    "            color='#3498db', fill=True, alpha=0.3, linewidth=2)\n",
    "sns.kdeplot(data=female_compound, ax=ax4, label=f'Female (Î¼={female_compound. mean():.3f})',\n",
    "            color='#e91e63', fill=True, alpha=0.3, linewidth=2)\n",
    "\n",
    "# Add mean lines\n",
    "ax4.axvline(x=male_compound. mean(), color='#3498db', linestyle='--', linewidth=2, alpha=0.8)\n",
    "ax4.axvline(x=female_compound.mean(), color='#e91e63', linestyle='--', linewidth=2, alpha=0.8)\n",
    "\n",
    "ax4.set_xlabel('Compound Score', fontsize=12)\n",
    "ax4.set_ylabel('Density', fontsize=12)\n",
    "ax4.set_title('Compound Score Density by Gender', fontsize=14, fontweight='bold')\n",
    "ax4.legend(loc='upper right')\n",
    "\n",
    "# Add p-value annotation\n",
    "ax4.text(0.02, 0.98, f'Mann-Whitney p={p_value_mw:.4f}\\nCohen\\'s d={cohens_d:.4f} ({effect_interpretation})',\n",
    "         transform=ax4.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.6_sentiment_by_gender_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "ff8bfed1db57dea1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Aggregate by user - average sentiment per user\n",
    "user_sentiment = df_supervised.groupby(['author', 'gender_label']).agg({\n",
    "    'sentiment_compound': ['mean', 'std', 'count'],\n",
    "    'sentiment_pos': 'mean',\n",
    "    'sentiment_neg': 'mean',\n",
    "    'sentiment_neu': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "user_sentiment.columns = ['author', 'gender_label', 'compound_mean', 'compound_std',\n",
    "                          'num_comments', 'pos_mean', 'neg_mean', 'neu_mean']\n",
    "\n",
    "print(\"User-level Sentiment Statistics:\")\n",
    "print(user_sentiment. groupby('gender_label').agg({\n",
    "    'compound_mean': ['mean', 'std', 'median'],\n",
    "    'num_comments': ['mean', 'sum']\n",
    "}).round(4))\n"
   ],
   "id": "7566af3aebe3a3d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# User-level statistical test\n",
    "male_users = user_sentiment[user_sentiment['gender_label'] == 'Male']['compound_mean'].dropna()\n",
    "female_users = user_sentiment[user_sentiment['gender_label'] == 'Female']['compound_mean']. dropna()\n",
    "\n",
    "stat_user, p_user = stats.mannwhitneyu(male_users, female_users, alternative='two-sided')\n",
    "\n",
    "print(f\"\\n--- USER-LEVEL ANALYSIS ---\")\n",
    "print(f\"Male users: n={len(male_users)}, mean={male_users.mean():.4f}\")\n",
    "print(f\"Female users:  n={len(female_users)}, mean={female_users.mean():.4f}\")\n",
    "print(f\"Mann-Whitney U p-value: {p_user:.6f}\")\n",
    "print(f\"Significant at Î±=0.05: {'YES' if p_user < 0.05 else 'NO'}\")\n"
   ],
   "id": "76f1858caaa7b5e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# User-level visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.kdeplot(data=male_users, ax=ax, label=f'Male (n={len(male_users)}, Î¼={male_users. mean():.3f})',\n",
    "            color='#3498db', fill=True, alpha=0.3, linewidth=2)\n",
    "sns.kdeplot(data=female_users, ax=ax, label=f'Female (n={len(female_users)}, Î¼={female_users.mean():.3f})',\n",
    "            color='#e91e63', fill=True, alpha=0.3, linewidth=2)\n",
    "\n",
    "ax.axvline(x=male_users.mean(), color='#3498db', linestyle='--', linewidth=2)\n",
    "ax.axvline(x=female_users.mean(), color='#e91e63', linestyle='--', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Average Compound Score per User', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('User-Level Average Sentiment by Gender', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "ax.text(0.02, 0.98, f'Mann-Whitney p={p_user:.4f}',\n",
    "        transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('4.7_sentiment_by_gender_user_level.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ],
   "id": "5311f30b041a54dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze if gender differences vary across subreddits\n",
    "gender_subreddit_sentiment = df_supervised.groupby(['subreddit', 'gender_label'])['sentiment_compound'].mean().unstack()\n",
    "\n",
    "# Filter to subreddits with enough data from both genders\n",
    "min_comments_per_gender = 50\n",
    "gender_counts = df_supervised. groupby(['subreddit', 'gender_label']).size().unstack(fill_value=0)\n",
    "\n",
    "# Check which columns exist\n",
    "if 'Male' in gender_counts.columns and 'Female' in gender_counts.columns:\n",
    "    valid_subreddits = gender_counts[(gender_counts['Male'] >= min_comments_per_gender) &\n",
    "                                      (gender_counts['Female'] >= min_comments_per_gender)].index\n",
    "\n",
    "    gender_subreddit_filtered = gender_subreddit_sentiment. loc[valid_subreddits]. copy()\n",
    "    gender_subreddit_filtered['difference'] = gender_subreddit_filtered['Female'] - gender_subreddit_filtered['Male']\n",
    "    gender_subreddit_filtered = gender_subreddit_filtered. sort_values('difference')\n",
    "\n",
    "    print(f\"Subreddits with >= {min_comments_per_gender} comments from each gender:  {len(valid_subreddits)}\")\n",
    "    print(\"\\nSubreddits where FEMALES are more positive than males:\")\n",
    "    print(gender_subreddit_filtered[gender_subreddit_filtered['difference'] > 0]. tail(10))\n",
    "    print(\"\\nSubreddits where MALES are more positive than females:\")\n",
    "    print(gender_subreddit_filtered[gender_subreddit_filtered['difference'] < 0].head(10))\n",
    "else:\n",
    "    print(\"Warning:  Missing gender data in some subreddits\")\n",
    "    gender_subreddit_filtered = None\n"
   ],
   "id": "b5d0ab6a8a28b9e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize gender differences across subreddits\n",
    "if gender_subreddit_filtered is not None and len(gender_subreddit_filtered) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Take top 10 from each direction\n",
    "    n_show = min(10, len(gender_subreddit_filtered) // 2)\n",
    "    if n_show > 0:\n",
    "        top_female_positive = gender_subreddit_filtered.tail(n_show)\n",
    "        top_male_positive = gender_subreddit_filtered.head(n_show)\n",
    "        plot_df = pd.concat([top_male_positive, top_female_positive])\n",
    "\n",
    "        colors_diff = ['#e91e63' if x > 0 else '#3498db' for x in plot_df['difference']]\n",
    "        ax.barh(plot_df. index, plot_df['difference'], color=colors_diff, edgecolor='black')\n",
    "\n",
    "        ax.axvline(x=0, color='black', linewidth=1)\n",
    "        ax.set_xlabel('Sentiment Difference (Female - Male)', fontsize=12)\n",
    "        ax.set_ylabel('Subreddit', fontsize=12)\n",
    "        ax.set_title('Gender Sentiment Difference by Subreddit', fontsize=14, fontweight='bold')\n",
    "\n",
    "        # Add legend\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [Patch(facecolor='#e91e63', label='Females more positive'),\n",
    "                           Patch(facecolor='#3498db', label='Males more positive')]\n",
    "        ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('4.8_sentiment_gender_difference_by_subreddit.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Not enough data for subreddit-gender interaction plot\")\n",
    "else:\n",
    "    print(\"Skipping subreddit-gender interaction plot due to missing data\")\n"
   ],
   "id": "b74f5f5e35050242",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SECTION 4 - SENTIMENT ANALYSIS:  SUMMARY OF FINDINGS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nðŸ“Š TASK 1a - PREPROCESSING:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ Used MINIMAL preprocessing for sentiment analysis\")\n",
    "print(\"â€¢ PRESERVED negation words (not, never, no) - crucial for sentiment!\")\n",
    "print(\"â€¢ PRESERVED punctuation (!  ?) and case sensitivity\")\n",
    "print(\"â€¢ REMOVED only URLs and Reddit-specific references (r/, u/)\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ TASK 1b - OVERALL SENTIMENT DISTRIBUTION:\")\n",
    "print(\"-\" * 50)\n",
    "for label in ['positive', 'neutral', 'negative']:\n",
    "    pct = sentiment_percentages. get(label, 0)\n",
    "    count = sentiment_counts.get(label, 0)\n",
    "    print(f\"â€¢ {label. capitalize():10s}:  {count:>7,} comments ({pct: >5.1f}%)\")\n",
    "\n",
    "print(\"\\nðŸ—‚ï¸ TASK 1c - SENTIMENT PER SUBREDDIT:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ Analyzed {df_supervised['subreddit'].nunique()} unique subreddits\")\n",
    "print(f\"â€¢ Most positive subreddit: {subreddit_compound_filtered.index[0]} (mean={subreddit_compound_filtered. iloc[0]['mean']:.3f})\")\n",
    "print(f\"â€¢ Most negative subreddit: {subreddit_compound_filtered.index[-1]} (mean={subreddit_compound_filtered.iloc[-1]['mean']:.3f})\")\n",
    "print(\"â€¢ Visualizations:  stacked bar chart, heatmap, extreme subreddits comparison\")\n",
    "\n",
    "print(\"\\nðŸ‘« TASK 1d - SENTIMENT vs GENDER:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"â€¢ Male comments: n={len(male_compound):,}, mean={male_compound. mean():.4f}\")\n",
    "print(f\"â€¢ Female comments: n={len(female_compound):,}, mean={female_compound.mean():.4f}\")\n",
    "print(f\"â€¢ Difference (Female - Male): {mean_diff: .4f}\")\n",
    "\n",
    "if mean_diff > 0:\n",
    "    print(\"â€¢ Finding:  Female users post SLIGHTLY MORE POSITIVE comments\")\n",
    "else:\n",
    "    print(\"â€¢ Finding: Male users post SLIGHTLY MORE POSITIVE comments\")\n",
    "\n",
    "print(f\"\\nâ€¢ Statistical Tests:\")\n",
    "print(f\"  - Mann-Whitney U p-value: {p_value_mw:.6f}\")\n",
    "print(f\"  - Significant at Î±=0.05: {'YES' if p_value_mw < 0.05 else 'NO'}\")\n",
    "print(f\"  - Effect size (Cohen's d): {cohens_d:.4f} ({effect_interpretation})\")\n",
    "\n",
    "print(\"\\nðŸ“ FILES GENERATED:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"â€¢ 4.1_sentiment_overall_distribution.png\")\n",
    "print(\"â€¢ 4.2_sentiment_by_subreddit_bar. png\")\n",
    "print(\"â€¢ 4.3_sentiment_by_subreddit_heatmap.png\")\n",
    "print(\"â€¢ 4.4_sentiment_extreme_subreddits.png\")\n",
    "print(\"â€¢ 4.5_sentiment_counts_by_subreddit.png\")\n",
    "print(\"â€¢ 4.6_sentiment_by_gender_analysis.png\")\n",
    "print(\"â€¢ 4.7_sentiment_by_gender_user_level.png\")\n",
    "print(\"â€¢ 4.8_sentiment_gender_difference_by_subreddit.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "# Save comment-level sentiment features\n",
    "sentiment_features = df_supervised[['author', 'subreddit', 'body',\n",
    "                                     'sentiment_compound', 'sentiment_pos',\n",
    "                                     'sentiment_neg', 'sentiment_neu',\n",
    "                                     'sentiment_label', 'gender', 'gender_label']].copy()\n",
    "sentiment_features.to_csv('sentiment_features_comments.csv', index=False)\n",
    "print(\"âœ“ Saved:  sentiment_features_comments.csv\")\n",
    "\n",
    "# Save user-level aggregated sentiment\n",
    "user_sentiment. to_csv('sentiment_features_users.csv', index=False)\n",
    "print(\"âœ“ Saved: sentiment_features_users. csv\")\n",
    "\n",
    "# Save subreddit-level sentiment summary\n",
    "subreddit_sentiment_summary = pd.DataFrame({\n",
    "    'subreddit': subreddit_compound_filtered.index,\n",
    "    'mean_compound': subreddit_compound_filtered['mean'],\n",
    "    'std_compound': subreddit_compound_filtered['std'],\n",
    "    'num_comments': subreddit_compound_filtered['count']\n",
    "})\n",
    "subreddit_sentiment_summary.to_csv('sentiment_by_subreddit.csv', index=False)\n",
    "print(\"âœ“ Saved: sentiment_by_subreddit.csv\")\n",
    "\n",
    "print(\"\\nâœ… All files saved successfully!\")\n",
    "print(\"\\nThese files can be used in Section 2 (Integration Challenge)\")\n",
    "print(\"to add sentiment features to the gender classification pipeline.\")"
   ],
   "id": "9d0a4ee0cdfe1100",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
